import pathlib, sys
import unicodedata
import numpy as np
directory = pathlib.Path(__file__).parent.absolute()
sys.path.append(str(directory.parent.parent))
import neural_network as nn
END_LINE = "\n"
TERMINATION_CHARS = {END_LINE}
FALLBACK_CHAR = " "
MIN_CHAR, MAX_CHAR = ord(" "), ord("~")
NUMBER_OF_CHARS_IN_RANGE = MAX_CHAR - MIN_CHAR + 1
MAX_CHARS_IN_DATA = 25
def char_to_num(char: str) -> int:
    n = ord(char)
    if char in TERMINATION_CHARS:
        return 0
    if not MIN_CHAR <= n < MAX_CHAR:
        return char_to_num(FALLBACK_CHAR)
    return n - MIN_CHAR + 1
def num_to_lower_char(n: int) -> str:
    if n == 0:
        return END_LINE
    return chr(n + MIN_CHAR - 1)
def normalize(message: str) -> str:
    nfkd_form = unicodedata.normalize('NFKD', message)
    return u"".join([c for c in nfkd_form if not unicodedata.combining(c)])
def to_one_hot_vector(nums, n_labels: int) -> np.ndarray:
    return np.eye(n_labels)[nums]
def message_to_one_hot(message: str) -> np.ndarray:
    return to_one_hot_vector([char_to_num(char) for char in message], NUMBER_OF_CHARS_IN_RANGE)
def format_one_hot_messages(data: np.ndarray) -> np.ndarray:
    data = data[-MAX_CHARS_IN_DATA:]
    padding = np.zeros([MAX_CHARS_IN_DATA - len(data), NUMBER_OF_CHARS_IN_RANGE]).flatten()
    return np.hstack([padding, data.flatten()])
NETWORK_INPUT_LAYER_SIZE = NUMBER_OF_CHARS_IN_RANGE * MAX_CHARS_IN_DATA
NETWORK_HIDDEN_LAYER_SIZE = 2**10
NETWORK_OUTPUT_LAYER_SIZE = NUMBER_OF_CHARS_IN_RANGE
network = nn.network.Network([
    nn.layers.Dense(NETWORK_INPUT_LAYER_SIZE, NETWORK_HIDDEN_LAYER_SIZE),
    nn.activations.ReLU(),
    
    nn.layers.Dense(NETWORK_HIDDEN_LAYER_SIZE, NETWORK_HIDDEN_LAYER_SIZE),
    nn.activations.ReLU(),
    nn.layers.Dense(NETWORK_HIDDEN_LAYER_SIZE, NETWORK_HIDDEN_LAYER_SIZE),
    nn.activations.ReLU(),
    nn.layers.Dense(NETWORK_HIDDEN_LAYER_SIZE, NETWORK_HIDDEN_LAYER_SIZE),
    nn.activations.ReLU(),
    
    nn.layers.Dense(NETWORK_HIDDEN_LAYER_SIZE, NUMBER_OF_CHARS_IN_RANGE),
    nn.activations.Softmax(),    
], loss=nn.losses.CategoricalCrossEntropy())from network_util import *
# How many candidates to consider for next character, chooses from highest ranked charters.
# If this value is one, then only the highest ranked character is over picked
# If a number is picked it will pick that many (N) highest ranked numbers
# You can set to util.NUMBER_OF_CHARS_IN_RANGE to make every result a candidate
# Treat this like "temperature" of creativity
CHOOSE_N_CANDIDATES_FROM_TOP = 2
# From the pool of candidates, whether the ranks should be considered when a choice is made
# If this is True, higher ranked caudates have a higher chance of being picked
# If False, all caudates are treated equally
USE_PROBABILITIES = True
# Path to saved network weights and biases. You do not need to include file extension
NETWORK_PATH = directory / "char-network-b"
# NETWORK_PATH = directory / "looped-train" / "char-network-v0"
def main() -> None:
     
    print(f"Loading network from {NETWORK_PATH}")
    
    network.load(str(NETWORK_PATH))
    if CHOOSE_N_CANDIDATES_FROM_TOP is None: 
        print(f"Choose next character based on random choice", "with probabilities" if USE_PROBABILITIES else "")
    elif CHOOSE_N_CANDIDATES_FROM_TOP == 1:
        print(f"Choose next character based on highest probability.")
    else:
        print(f"Choose next character based on random choice from top {CHOOSE_N_CANDIDATES_FROM_TOP}", "with probabilities." if USE_PROBABILITIES else "")
    print()    
    while True:
        message = input("CharGPN> ")
        print(message, end="")
        # while (len(message) == 0 or message[-1] not in TERMINATION_CHARS) and (message.count(".") < 3):
        # while (len(message) == 0 or message.count(END_LINE) < 3):
        # while (len(message) == 0 or message[-1] not in TERMINATION_CHARS):
        while (len(message) < 2 or message[-2] not in ".\n"):
            output = network.compute(format_one_hot_messages(message_to_one_hot(message)))[0]
            top_indices = np.argsort(output)[-(CHOOSE_N_CANDIDATES_FROM_TOP if CHOOSE_N_CANDIDATES_FROM_TOP is not None else len(output)):]
            top_probabilities = output[top_indices]
            normalized_probabilities = top_probabilities / top_probabilities.sum()
            selected = np.random.choice(top_indices, p=normalized_probabilities)
            char = num_to_lower_char(selected)
            print(char, end="")
            message += char
        print("\n")
if __name__ == "__main__":
    main()import tkinter as tk
import numpy as np
from network_util import *
# Parameters for prediction behavior
CHOOSE_N_CANDIDATES_FROM_TOP = 1
# NETWORK_PATH = directory / "char-network-b"
NETWORK_PATH = directory / "looped-train" / "char-network-v2"
# Load the network model
network.load(str(NETWORK_PATH))
def predict_next_character_probs(message, n = 7):
    output = network.compute(format_one_hot_messages(message_to_one_hot(message)))[0]
    top_indices = np.argsort(output)[:-n-1:-1]
    top_probabilities = output[top_indices]
    normalized_probabilities = top_probabilities / top_probabilities.sum()
    return top_indices, normalized_probabilities
def predict_next_word(message, max_len = 28):
    word = ""
    while (word == "" or not word[-1].isspace()) and len(word) < max_len:
        output = network.compute(format_one_hot_messages(message_to_one_hot(message + word)))[0]
        top_indices = np.argsort(output)[-CHOOSE_N_CANDIDATES_FROM_TOP:]
        top_probabilities = output[top_indices]
        normalized_probabilities = top_probabilities / top_probabilities.sum()
        selected = np.random.choice(top_indices, p=normalized_probabilities)
        char = num_to_lower_char(selected)
        word += char
    return word
# Tkinter application setup
class TextPredictorApp:
    def __init__(self, root):
        self.root = root
        self.root.title(f"Text Predictor {NETWORK_PATH.name}")
        # Layout for text box and bar graph canvas
        self.frame = tk.Frame(root)
        self.frame.pack(padx=20, pady=20)
        # Text input box
        self.text_box = tk.Text(self.frame, height=20, width=50)
        self.text_box.grid(row=0, column=0)
        # Canvas for bar graph
        self.canvas = tk.Canvas(self.frame, width=300, height=200, bg="white")
        self.canvas.grid(row=0, column=1, padx=20)
        # Label for predicted word
        self.predicted_word_label = tk.Label(self.frame, text="Next word prediction:", font=("Arial", 12))
        self.predicted_word_label.grid(row=1, column=0, sticky="w")
        self.update_prediction()
        # Bind text box to events
        self.text_box.bind("<KeyRelease>", self.update_prediction)
        self.text_box.bind("<Key>", self.key)
        # Predicted word state
        self.predicted_word = ""
    def key(self, event=None):        
        if event and event.char == "\t":
            self.text_box.insert(tk.END, self.predicted_word)
            return "break"
    def update_prediction(self, event=None):
        current_message = self.text_box.get("1.0", "end-1c")
        top_indices, probabilities = predict_next_character_probs(current_message)
        self.update_bar_graph(top_indices, probabilities)
        self.predicted_word = predict_next_word(current_message)
        self.predicted_word_label.config(text=f"Prediction: {repr(self.predicted_word)}")
    def update_bar_graph(self, top_indices, probabilities):
        # Clear previous graph
        self.canvas.delete("all")
        # Define bar graph dimensions
        bar_width = 20
        spacing = 10
        x_offset = 50
        max_height = 150
        # Draw the bar graph for the top 10 characters
        for i, (index, prob) in enumerate(zip(top_indices, probabilities)):
            char = num_to_lower_char(index)
            bar_height = max_height * prob
            x0 = i * (bar_width + spacing) + x_offset
            y0 = max_height - bar_height
            x1 = x0 + bar_width
            y1 = max_height
            self.canvas.create_rectangle(x0, y0, x1, y1, fill="blue")
            self.canvas.create_text(x0 + bar_width / 2, y1 + 15, text=repr(char), font=("Arial", 10))
    def clear_bar_graph(self):
        self.canvas.delete("all")
# Initialize the GUI application
if __name__ == "__main__":
    root = tk.Tk()
    app = TextPredictorApp(root)
    root.mainloop()
# Quick project I assumed would fail so bad code quality
import csv, time, os
from network_util import *
import numpy as np
DATA_POINTS_PER_MESSAGE = 1
MIN_MESSAGE_SIZE = 3
EPOCHS = 3
BATCH_SIZE = 16
LEARNING_RATE = 0.005
OUTPUT_FOLDER = directory / "looped-train"
TRAINING_DATA_PATH = directory / "data" / "data.txt"
os.makedirs(OUTPUT_FOLDER, exist_ok=True)
print("Loading Data...")
LOAD_NETWORK_AT_START = directory / "char-network-a"
if LOAD_NETWORK_AT_START is not None:
    network.load(str(LOAD_NETWORK_AT_START))
with open(TRAINING_DATA_PATH, "r", encoding="utf-8") as file:
    messages = [normalize(line).strip() for line in file.readlines()]
    messages = [message + END_LINE for message in messages if len(message) > MIN_MESSAGE_SIZE]
    
print("Formatting Data...")
computer_readable_messages = [message_to_one_hot(message) for message in messages]
X_train = np.empty(shape=(len(computer_readable_messages) * DATA_POINTS_PER_MESSAGE, NETWORK_INPUT_LAYER_SIZE))
y_train = np.empty(shape=(len(computer_readable_messages) * DATA_POINTS_PER_MESSAGE, NETWORK_OUTPUT_LAYER_SIZE))
print(f"""
        Using {len(computer_readable_messages):,} messages to create {len(X_train):,} data points to train on, repeated {EPOCHS:,} times.
        That is {X_train.nbytes // 2**20:,} MB of data.
        Training happens in batches of {BATCH_SIZE} with a learning rate of {LEARNING_RATE:%}.
    """)
print("Training in loop...")
print("Stop at any round and view result")
print()
for i in range(100):
    print(f"Round {i:,}. Beginning at {time.ctime(time.time())}")
    for message_index, message in enumerate(computer_readable_messages):
        for place_index in range(DATA_POINTS_PER_MESSAGE):
            train_index = message_index * DATA_POINTS_PER_MESSAGE + place_index
            
            rand_index = np.random.randint(MIN_MESSAGE_SIZE - 1, len(message) - 1)
            
            X_train[train_index] = format_one_hot_messages(message[:rand_index])
            y_train[train_index] = message[rand_index]
    network.train(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, learning_rate=LEARNING_RATE)
    network.dump(str(OUTPUT_FOLDER / f"char-network-v{i}"))
    print()
import csv
import unicodedata
import pathlib
directory = pathlib.Path(__file__).parent.absolute()
def normalize(message: str) -> str:
    nfkd_form = unicodedata.normalize('NFKD', message)
    return u"".join([c for c in nfkd_form if not unicodedata.combining(c)])
# --- Read Write ---
# with open(input_filename, 'r', encoding="utf-8") as file:
#     content = file.read()
# modified_content = content.replace('. ', '.\n')
# with open(output_filename, 'w', encoding="utf-8") as file:
#     file.write(modified_content)
# print(f"Newlines inserted after periods and saved to {output_filename}")
# --- Read Write ---
# with open(directory / "data.txt", "r", encoding="utf-8") as file:
#     data = csv.reader(file.readlines())
#     messages = [normalize(line[3]) for line in data if len(line) > 3]
# with open(directory / "data.txt", "w", encoding="utf-8") as file:
#     file.writelines(messages)
    
# --- Read Write ---
    
# with open("starwars.csv", "r", encoding="utf-8") as file:
#     data = [line.split('" "')[-1][:-2] + "\n" for line in file.readlines()]
# with open("starwars.txt", "w", encoding="utf-8") as file:
#     file.writelines(data)
# --- Read Write ---
import os
def get_python_files(path):
    python_files = []
    for root, _, files in os.walk(path):
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                if ".venv" not in file_path:
                    python_files.append(file_path)
    return python_files
data = []
for path in get_python_files(directory.parent.parent.parent):
    print(path)
    with open(path, "r", encoding="utf-8") as file:
        data.extend(file.readlines())
with open(directory / "data.txt", "w", encoding="utf-8") as file:
    file.writelines([line for line in data if len(line) > 4])
import pickle
small_drawing_width, small_drawing_height = (28, 28)
save_file_name = "mnist_train_test.pkl"
def save(directory, log = False):
    from keras.datasets.mnist import load_data
    (X_train, y_train), (X_test, y_test) = load_data()
    if log:
        print(X_train.dtype, X_train.shape)
        print(y_train.dtype, y_train.shape)
        print(X_test.dtype, X_test.shape)
        print(y_test.dtype, y_test.shape)
    data = ((X_train.shape[0], X_train.tobytes(), y_train.tobytes()), (X_test.shape[0], X_test.tobytes(), y_test.tobytes()))
    with open(directory / save_file_name, "wb") as file:
        pickle.dump(data, file)
        
def load(directory, log = False):
    import numpy as np
    
    with open(directory / save_file_name, "rb") as file:
        ((train_len, X_train, y_train), (test_len, X_test, y_test)) = pickle.load(file)
        
    X_train = np.frombuffer(X_train, dtype=np.uint8).reshape((train_len, small_drawing_height, small_drawing_width))
    y_train = np.frombuffer(y_train, dtype=np.uint8).reshape((train_len,))
    
    X_test = np.frombuffer(X_test, dtype=np.uint8).reshape((test_len, small_drawing_height, small_drawing_width))
    y_test = np.frombuffer(y_test, dtype=np.uint8).reshape((test_len,))
    
    if log:
        print(X_train.dtype, X_train.shape)
        print(y_train.dtype, y_train.shape)
        print(X_test.dtype, X_test.shape)
        print(y_test.dtype, y_test.shape)
    
    return (X_train, y_train), (X_test, y_test)print("Loading modules...")
import pathlib
import sys
"""Result: unsurprising just always predicts the most common letter, e"""
directory = pathlib.Path(__file__).parent.absolute()
sys.path.append(str(directory.parent.parent))
import tkinter as tk
import numpy as np
from matplotlib import pyplot as plt
import neural_network as nn
import data_saver
# --- get data and set constants ---
print("Loading data...")
# (X_train, y_train), (X_test, y_test) = load_data()
# small_drawing_width, small_drawing_height = X_train[0].shape
small_drawing_width, small_drawing_height = (28, 28) 
large_drawing_width, large_drawing_height = (400, 400)
# n_inputs, n_outputs = small_drawing_width * small_drawing_height, y_train.max() + 1
n_inputs, n_outputs = small_drawing_width * small_drawing_height, 10
layer_size = 2**8
# --- Define neural network and get params for it ---
def shift_up(array: np.ndarray) -> np.ndarray:
    indices = np.argwhere(array > 0)
    
    if len(indices) == 0:
        return array
    min_row, min_col = indices.min(axis=0)
    row_shift = -min_row
    col_shift = -min_col
    shifted_array = np.roll(array, row_shift, axis=0)
    shifted_array = np.roll(shifted_array, col_shift, axis=1)
    
    return shifted_array
def apply_all(arrays: np.ndarray, func) -> np.ndarray:
    if arrays.ndim < 3: return func(arrays)
    
    new = np.empty_like(arrays)
    for i, array in enumerate(arrays): new[i] = func(array)
    return new
def preprocess(inputs):
    inputs = inputs.astype(np.float64) / 255
    inputs = apply_all(inputs, shift_up)
    return inputs
network = nn.network.Network([
    nn.layers.Reshape((small_drawing_width, small_drawing_height), (n_inputs,)),
    nn.layers.Dense(n_inputs, layer_size),
    nn.activations.ReLU(),
    nn.layers.Dense(layer_size, layer_size),
    nn.activations.ReLU(),
    
    nn.layers.Dense(layer_size, layer_size),
    nn.activations.ReLU(),
    
    nn.layers.Dense(layer_size, n_outputs),
    nn.activations.Softmax(),
], loss=nn.losses.CategoricalCrossEntropy(categorical_labels=True), preprocess=[preprocess])
save_file = str(directory / "mnist-network")
try:
    print(f"Attempting to load saved network from {save_file}...")
    network.load(save_file)
except FileNotFoundError:
    print("No saved network found, getting training data")
    
    (X_train, y_train), (X_test, y_test) = data_saver.load(directory)
     
    print("Starting Training...")
    network.train(X_train, y_train, batch_size=16, epochs=2, learning_rate=0.1)
    network.dump(save_file)
    # --- test model on test data ---
    test_output = network.compute(X_test)
    predictions = test_output.argmax(1)
    accuracy = np.mean(predictions == y_test)
    
    print(f"{accuracy:%} accurate on test data")
    # print("\nDisplaying tests...")
    # for num in range(0, n_outputs):
    #     index = np.random.choice(np.where(y_test == num)[0])
    #     output = test_output[index]
    #     guess = output.argmax()
    #     print(f"y_pred={output.tolist()}, y_true={np.eye(n_outputs)[guess]}")
    #     plt.title(
    #         f"Test Data Example {num}:\n{guess=}, confidence={output[guess]:.2%}, correct={guess==num}")
    #     plt.imshow(X_test[index], cmap="Greys")
    #     plt.show()
# --- create drawing GUI ---
def draw_dot(array: np.ndarray, row: int, col: int, value: float) -> None:
    if -1 < row < np.size(array, 1) and -1 < col < np.size(array, 0):
        array[row, col] = min(array[row, col] + ((1 - value) * 255), 255)
def draw_blob(array, row, col, value):
    draw_dot(array, row, col, value)
    value_edge = 1 - (1-value) / 5
    draw_dot(array, row+1, col, value_edge)
    draw_dot(array, row, col+1, value_edge)
    draw_dot(array, row-1, col, value_edge)
    draw_dot(array, row, col-1, value_edge)
    value_corner = 1 - (1-value) / 10
    draw_dot(array, row+1, col+1, value_corner)
    draw_dot(array, row-1, col+1, value_corner)
    draw_dot(array, row+1, col-1, value_corner)
    draw_dot(array, row-1, col-1, value_corner)
def draw_line(array: np.ndarray, row1: int, col1: int, row2: int, col2: int):
    col_distance = abs(col1 - col2)
    row_distance = abs(row1 - row2)
    error = col_distance - row_distance
    last_error = 0
    col_change = 1 if col1 < col2 else -1
    row_change = 1 if row1 < row2 else -1
    distance_change = 1 if col_distance + row_distance == 0 else \
        np.sqrt(col_distance*col_distance + row_distance*row_distance)
    current_col, current_row = col1, row1
    while True:
        draw_blob(array, current_row, current_col,
                  np.abs(error - col_distance + row_distance) / distance_change)
        last_error = error
        last_col = current_col
        if 2 * last_error >= -col_distance:
            if current_col == col2:
                break
            if (last_error + row_distance) < distance_change:
                draw_blob(array, current_row + row_change, current_col,
                          np.abs(last_error + row_distance) / distance_change)
            error -= row_distance
            current_col += col_change
        if 2 * last_error <= row_distance:
            if current_row == row2:
                break
            if (col_distance - last_error) < distance_change:
                draw_blob(array, current_row, last_col + col_change,
                          np.abs(col_distance - last_error) / distance_change)
            error += col_distance
            current_row += row_change
class DrawingDisplay:
    def __init__(self, canvas: tk.Canvas, save_size: tuple[int, int], on_update=lambda pixels: None, on_reset=lambda: None) -> None:
        self.canvas = canvas
        self.canvas.config(cursor="crosshair")
        self.canvas_width, self.canvas_height = self.canvas.winfo_reqheight(), self.canvas.winfo_reqwidth()
        self.pixel_array = np.zeros(save_size, dtype=int)
        self.canvas.bind("<B1-Motion>", self.draw)
        self.canvas.bind("<Button-1>", self.start_draw)
        self.on_update = on_update
        self.on_reset = on_reset
        self.previous_draw_point = (None, None)
        self.buttons = [
            tk.Button(self.canvas.master, text="Clear Drawing", command=self.clear_canvas),
            tk.Button(self.canvas.master, text="Display Raw Data", command=self.show_graph),
            tk.Button(self.canvas.master, text="Display Processed Data", command=self.show_processed_graph),
        ]
        self.pen_size = 5
    def start_draw(self, event: tk.Event) -> None:
        self.previous_draw_point = (event.x, event.y)
        size = self.pen_size / 2
        self.canvas.create_oval(
            event.x+size, event.y+size, event.x-size, event.y-size, fill="black", tags="line")
        row, col = self.scale_for_save(event.x, event.y)
        draw_blob(self.pixel_array, row, col, 0)
        self.on_update(self.pixel_array)
    def draw(self, event: tk.Event) -> None:
        prev_x, prev_y = self.previous_draw_point
        self.previous_draw_point = (event.x, event.y)
        self.canvas.create_line(event.x, event.y, prev_x, prev_y,
                                fill="black", smooth=True, width=self.pen_size)
        row1, col1 = self.scale_for_save(event.x, event.y)
        row2, col2 = self.scale_for_save(prev_x, prev_y)
        draw_line(self.pixel_array, row1, col1, row2, col2)
        self.on_update(self.pixel_array)
    def scale_for_save(self, x: float, y: float) -> tuple[int, int]:
        row = round(y / self.canvas_width * (np.size(self.pixel_array, 0) - 1))
        col = round(x / self.canvas_height * (np.size(self.pixel_array, 1) - 1))
        return row, col
    def clear_canvas(self) -> None:
        self.pixel_array = np.zeros_like(self.pixel_array)
        self.canvas.delete(tk.ALL)
        self.on_reset()
    def show_graph(self) -> None:
        pixels = self.pixel_array
        plt.imshow(pixels, cmap="Greys")
        print("\n".join((" ".join(str(pixel).ljust(3) for pixel in row)) for row in self.pixel_array), "\n")
        plt.show()
        
    def show_processed_graph(self) -> None:
        pixels = preprocess(self.pixel_array)
        plt.imshow(pixels, cmap="Greys")
        print("\n".join((" ".join(str(round(pixel, 3)).ljust(5) for pixel in row)) for row in pixels), "\n")
        plt.show()
    def place_buttons(self) -> None:
        button_canvas = tk.Canvas(self.canvas)
        button_canvas.place(in_=self.canvas, relx=0.0, rely=1.0)
        for button in self.buttons:
            button.pack(in_=button_canvas, side="left", padx=5, pady=5)
class NetworkInfoDisplay:
    def __init__(self, canvas: tk.Canvas, n_neurons: int) -> None:
        self.canvas = canvas
        self.sub_canvas_size = 40
        self.n_neurons = n_neurons
        self.neuron_canvases = [tk.Canvas(
            self.canvas, width=self.sub_canvas_size, height=self.sub_canvas_size) for n in range(self.n_neurons)]
        self.percent_canvases = [tk.Canvas(
            self.canvas, width=self.sub_canvas_size*1.5, height=self.sub_canvas_size) for n in range(self.n_neurons)]
        for index, item in enumerate(self.neuron_canvases):
            item.grid(column=0, row=index, pady=3)
        for index, item in enumerate(self.percent_canvases):
            item.grid(column=1, row=index, pady=3)
    def update(self, outputs: np.ndarray):
        for index, (output, neuron_canvas, percent_canvas) in enumerate(zip(outputs, self.neuron_canvases, self.percent_canvases)):
            brightness = int((1-output) * 255)
            neuron_canvas.delete(tk.ALL)
            neuron_canvas.create_oval(3, 3, self.sub_canvas_size, self.sub_canvas_size, outline="black",
                                      offset="n", fill="#%02x%02x%02x" % (brightness, brightness, brightness))
            neuron_canvas.create_text(self.sub_canvas_size/1.9, self.sub_canvas_size/1.9,
                                      fill=("white" if brightness < 200 else "black"), text=str(index), justify="center", font=("Arial", int(self.sub_canvas_size * 0.25)))
            percent_canvas.delete(tk.ALL)
            percent_canvas.create_text(self.sub_canvas_size/1.9, self.sub_canvas_size/1.9,
                                       text=format(output, ".0%"), justify="center", font=("Arial", int(self.sub_canvas_size * 0.25)))
    def reset(self):
        self.update(np.zeros(self.n_neurons))
class GuessDisplay:
    def __init__(self, canvas: tk.Canvas) -> None:
        self.canvas = canvas
    def update(self, outputs: np.ndarray):
        guess = outputs.argmax()
        confidence = outputs[guess]
        # made by ChatGPT
        confidence_levels = [
            "I'm completely clueless about this, maybe it's a",
            "I really can't say for sure, perhaps it's a",
            "I have no strong feelings, but maybe it's a",
            "I'm not entirely sure, but it could be a",
            "I'm not too confident, but maybe a",
            "It's a wild guess, but maybe a",
            "I have a slight inkling, it might be a",
            "I'm leaning towards this, it could be a",
            "I'm somewhat confident, it might be a",
            "I'm not fully convinced, but possibly a",
            "I'm moderately confident, it could be a",
            "I'm getting more certain, it might be a",
            "I'm fairly confident, it's likely a",
            "I'm feeling quite sure, it could be a",
            "I'm fairly certain, it might be a",
            "I'm pretty confident, it seems to be a",
            "I'm quite sure, it's probably a",
            "I'm almost certain, it could be a",
            "I'm highly confident, it's very likely a",
            "I'm nearly 100% sure, it must be a",
            "That's obviously a",
        ]
        self.canvas.delete(self.canvas.delete(tk.ALL))
        smallest_max = 1 / len(outputs)
        self.canvas.create_text(large_drawing_width/2, large_drawing_height/10, justify="center",
                                text=confidence_levels[int((confidence - smallest_max) / (1 - smallest_max) * (len(confidence_levels) - 1))],
                                font=("Arial", int(large_drawing_height * 0.03)))
        self.canvas.create_text(large_drawing_width/2, large_drawing_height/2, justify="center",
                                text=str(guess),
                                font=("Arial", int(large_drawing_height * 0.5)))
        # self.canvas.create_text(large_drawing_width/2, large_drawing_height - large_drawing_height/10, justify="center",
        #                         text=format(confidence, "%"))
    def reset(self):
        self.canvas.delete(tk.ALL)
def main():
    root = tk.Tk()
    root.title("MNIST Drawing Test")
    root.resizable(width=False, height=False)
    
    drawing_canvas = tk.Canvas(root, background="white", highlightbackground="grey",
                            width=large_drawing_width, height=large_drawing_height)
    drawing_canvas.grid(row=0, column=0, padx=10, pady=10)
    network_info_canvas = tk.Canvas(root, width=20, height=large_drawing_height)
    network_info_canvas.grid(row=0, column=1, padx=10, pady=10)
    network_info = NetworkInfoDisplay(network_info_canvas, n_outputs)
    guess_canvas = tk.Canvas(root, background="white", highlightbackground="grey",
                            width=large_drawing_width, height=large_drawing_height)
    guess_canvas.grid(row=0, column=2, padx=10, pady=10)
    guess_info = GuessDisplay(guess_canvas)
    def reset():
        guess_info.reset()
        network_info.reset()
    def update(pixels: np.ndarray):
        # do neural network stuff here
        output = network.compute(np.array([pixels]))[0]
        print(", ".join(f"{num}: {chance:.5%}" for num, chance in enumerate(output)))
        
        network_info.update(output)
        guess_info.update(output)
    drawing_board = DrawingDisplay(
        drawing_canvas, (small_drawing_width, small_drawing_height), update, reset)
    drawing_board.place_buttons()
    reset()
    print("\nDisplaying drawing demo.")
    root.mainloop()
if __name__ == "__main__":
    main()import pygame
from utils import RelativeRectPoint
class Ball(pygame.sprite.Sprite):
    def __init__(self, size: int, start_position: RelativeRectPoint, start_slope: tuple[int, int], start_velocity: int, max_velocity: int) -> None:
        super().__init__()   
        self.image = pygame.Surface((size, size))
        self.image.fill("white")
        
        self.rect = self.image.get_rect() 
        self.start_velocity = start_velocity
        self.max_velocity = max_velocity
        
        self.start_position = start_position
        self.start_slope = start_slope
        self.to_starting_position()
        
    
    def set_new_motion(self, position: RelativeRectPoint, slope: tuple[int, int]) -> None:
        self.velocity = self.start_velocity
        
        self.rect.center = position.point
        self.y_change, self.x_change = slope
    
    def to_starting_position(self, to_reverse_side = False):
        self.set_new_motion(self.start_position.flip(flip_x=to_reverse_side), (self.start_slope[0], self.start_slope[1] * (-1 if to_reverse_side else 1)))
        
    def bounce_y(self) -> None:
        self.y_change *= -1
    def bounce_x(self) -> None:
        self.x_change *= -1
    
    @property
    def x_velocity(self) -> int:
        return int(self.x_change * self.velocity)
    
    @property
    def y_velocity(self) -> int:
        return int(self.y_change * self.velocity)
    def add_velocity(self, amount: float) -> None:
        self.velocity = min(self.velocity + amount, self.max_velocity)
    def update(self) -> None:
        self.rect.centerx += self.x_velocity
        self.rect.centery += self.y_velocity
        from time import sleep
import pygame
from ball import Ball
from player import AiPaddle, HumanPaddle, WallPaddle
from utils import RelativeRectPoint
def make_screen_size(size_px: int, aspect_ration: float, horizontal: bool = True) -> tuple[int, int]:
    return int(size_px * ((aspect_ration * (horizontal)) or 1)), int(size_px * ((aspect_ration * (not horizontal)) or 1))
class GameConstants:
    BACKGROUND_COLOR = "black"
    MAP_ITEM_COLOR = "white"
    
    WINDOW_NAME = "Pong Game"
    FRAMERATE = 60
    SCORE_TO_WIN = 10
    SCORE_LOCATION = 0.45, 0.05
    LINE_LOCATION = 0.5, 1
class BallConstants:
    SIZE = 10
    
    START_VELOCITY = 4
    MAX_VELOCITY = 12
    START_LOCATION = 0.07, 0.1
    START_SLOPE = 0.5, 1
    BOUNCE_VELOCITY_INCREASE = 0.25
class PaddleConstants:
    START_LOCATION = 0.06, 0.5
    PADDLE_SIZE = 0.005, 0.15
    
    TOP_AREA_SIZE = 1
def main() -> None:
    pygame.init()
    print()
    
    print("1 for Human, 2 for AI, 3 for Wall")
    right_player_type = input("Right Player Type: ").lower().strip()
    
    screen = pygame.display.set_mode(
        make_screen_size(size_px=400, aspect_ration=16/10, horizontal=True), 
        flags = pygame.RESIZABLE
    )
    pygame.display.set_caption(GameConstants.WINDOW_NAME)
    clock = pygame.time.Clock()
    font = pygame.font.Font('freesansbold.ttf', 32)
    ball = Ball(
        BallConstants.SIZE, RelativeRectPoint(screen, BallConstants.START_LOCATION),
        BallConstants.START_SLOPE, BallConstants.START_VELOCITY,  BallConstants.MAX_VELOCITY
    )
    left_player = HumanPaddle(
        RelativeRectPoint(screen, PaddleConstants.START_LOCATION, reverse_x=False),
        RelativeRectPoint(screen, PaddleConstants.PADDLE_SIZE),
        pygame.K_q, pygame.K_a
    )
    if right_player_type in ("2", "ai"):
        right_player = AiPaddle(
            RelativeRectPoint(screen, PaddleConstants.START_LOCATION, reverse_x=True),
            RelativeRectPoint(screen, PaddleConstants.PADDLE_SIZE),
        )
    elif right_player_type in ("3", "wall"):
        right_player = WallPaddle(
            RelativeRectPoint(screen, PaddleConstants.START_LOCATION, reverse_x=True),
            RelativeRectPoint(screen, PaddleConstants.PADDLE_SIZE),
        )
    else:
        right_player = HumanPaddle(
            RelativeRectPoint(screen, PaddleConstants.START_LOCATION, reverse_x=True),
            RelativeRectPoint(screen, PaddleConstants.PADDLE_SIZE),
            pygame.K_p, pygame.K_l
        )
    
    players = pygame.sprite.Group([left_player, right_player])  # type: ignore
    
    all_sprites = pygame.sprite.Group([*players, ball])  # type: ignore
    def draw_score() -> None:
        left_player_score_font = font.render(str(left_player.score), True, GameConstants.MAP_ITEM_COLOR)
        screen.blit(
            left_player_score_font,
            RelativeRectPoint(screen, GameConstants.SCORE_LOCATION, reverse_x=False).point_centered_for(left_player_score_font)
        )
        
        right_player_score_font = font.render(str(right_player.score), True, GameConstants.MAP_ITEM_COLOR)
        screen.blit(
            right_player_score_font,
            RelativeRectPoint(screen, GameConstants.SCORE_LOCATION, reverse_x=True).point_centered_for(right_player_score_font)
        )
        
    frame = 0
    
    while not pygame.event.get(pygame.QUIT):
        frame += 1
        
        if frame % 2 == 0:
            screen.fill(GameConstants.BACKGROUND_COLOR)
    
        pygame.draw.line(screen, GameConstants.MAP_ITEM_COLOR,
                RelativeRectPoint(screen, GameConstants.LINE_LOCATION, reverse_y=False).point,
                RelativeRectPoint(screen, GameConstants.LINE_LOCATION, reverse_y=True).point)
        
        all_sprites.update()
         
        for player in players:
            player.rect.clamp_ip(screen.get_rect()) 
        
        if isinstance(left_player, AiPaddle):
            left_player.find_next_move(ball, screen)
            
        if isinstance(right_player, AiPaddle):
            right_player.find_next_move(ball, screen)
        collisions = pygame.sprite.spritecollide(ball, players, False)
        if collisions:
            collision_paddle = collisions[0].rect
            if abs(ball.rect.right - collision_paddle.left) < ball.max_velocity or abs(ball.rect.left - collision_paddle.right) < ball.max_velocity:
                ball.bounce_x()
            if abs(ball.rect.top - collision_paddle.bottom) < ball.max_velocity or abs(ball.rect.bottom - collision_paddle.top) < ball.max_velocity:
                ball.bounce_y()
            ball.add_velocity(BallConstants.BOUNCE_VELOCITY_INCREASE)
        
        if ball.rect.right < screen.get_rect().left:
            # ball went over left side of wall
            ball.to_starting_position(to_reverse_side=True)
            right_player.add_score()
        
        elif ball.rect.left > screen.get_rect().right:
            # ball went over right side of wall
            ball.to_starting_position(to_reverse_side=False)
            left_player.add_score()     
        if ball.rect.top < screen.get_rect().top or ball.rect.bottom > screen.get_rect().bottom:
            # ball hit top or bottom
            ball.bounce_y()
        draw_score()
        all_sprites.draw(screen)
        pygame.display.update()
        clock.tick(GameConstants.FRAMERATE)
if __name__ == "__main__":
    main()
import pygame
from ball import Ball
from utils import RelativeRectPoint
class Constants:
    SPEED = 5
    COLOR = "white"
class Paddle(pygame.sprite.Sprite):
    def __init__(self, start_position: RelativeRectPoint, size: RelativeRectPoint) -> None:
        super().__init__()
        
        self.start_position = start_position
        
        self.score = 0
        self.size = size
            
        self.image = pygame.Surface(self.size.point)
        self.image.fill(Constants.COLOR)
        
        self.rect = self.image.get_rect()
                
        self.rect.centery = self.start_position.y
        
    def add_score(self) -> None:
        self.score += 1
                    
    def go_up(self) -> None:
        self.rect.y -= Constants.SPEED
    
    def go_down(self) -> None:
        self.rect.y += Constants.SPEED
    
    def update(self) -> None:
        self.rect.centerx = self.start_position.x
class HumanPaddle(Paddle):
    def __init__(self, start_position: RelativeRectPoint, size: RelativeRectPoint, up_key, down_key) -> None:
        super().__init__(start_position, size)
            
        self.up_key = up_key
        self.down_key = down_key
        
    def update(self) -> None:
        super().update()
                
        keys = pygame.key.get_pressed()
        
        if keys[self.up_key]: self.go_up()
        if keys[self.down_key]: self.go_down()
        
        
class AiPaddle(Paddle):
    def __init__(self, start_position: RelativeRectPoint, size: RelativeRectPoint) -> None:
        super().__init__(start_position, size)
        self.action = None
    
    def find_next_move(self, ball: Ball, screen: pygame.Surface) -> None:
        y = self.rect.centery
        ball_y = ball.rect.centery
        
        difference = y - ball_y
        
        if difference > 5:
            self.action = self.go_up
        elif difference < 5:
            self.action = self.go_down
        else:
            self.action = None
    
    def update(self) -> None:
        super().update()
        if self.action: self.action()
class WallPaddle(Paddle):
    def __init__(self, start_position: RelativeRectPoint, size: RelativeRectPoint) -> None:
        size._y = 1
        super().__init__(start_position, size)  import pygame
class RelativeRectPoint:
    __slots__ = ("_base_surface", "_x", "_y")
    
    def __init__(self, base: pygame.Surface, point: tuple[float, float], *, reverse_x = False, reverse_y = False) -> None:
        self._base_surface = base
        self._x, self._y = point
        if reverse_x: self._x = 1 - self._x
        if reverse_y: self._y = 1 - self._y
         
    @property
    def x(self) -> int: return round(self._base_surface.get_width() * self._x)
    
    @property
    def y(self) -> int: return round(self._base_surface.get_height() * self._y)
    
    @property
    def point(self) -> tuple[int, int]: return (self.x, self.y)
    
    def __getitem__(self, index) -> int: return self.point[index]
    def flip(self, flip_x = False, flip_y = False) -> "RelativeRectPoint":
        return self.__class__(self._base_surface, (self._x, self._y), reverse_x=flip_x, reverse_y=flip_y)
    
    def point_centered_for(self, surface: pygame.Surface) -> tuple[int, int]:
        return (self.x - (surface.get_width() // 2), self.y - (surface.get_height() // 2))import time
import datetime
import numpy as np
import constants
from dqn_agent import DQNAgent
from tetris import Tetris
# Run dqn with Tetris
def main():
    fps = 1
    
    env = Tetris(
        constants.BOARD_WIDTH, constants.BOARD_HEIGHT, shape_queue_size=constants.SHAPE_QUEUE_SIZE,
        FPS=fps, enable_wall_kick=True, enable_hold=False,
    )
    
    episodes = 1_000_000
    epsilon_stop_episode = 15_000
    epsilon_start = 10 / 100
    max_steps = float("inf")
    batch_size = 512
    epochs = 1
    
    train_every = fps
    log_every = 100
    
    agent = DQNAgent(constants.AGENT_NAME, env.state_as_array().size,
                     learning_rate=0.01,
                     epsilon_stop_episode=epsilon_stop_episode,
                     mem_size=10_000,
                     discount=0.95,
                     replay_start_size=6000,
                     epsilon=epsilon_start)
    agent.load()
    scores = []
    average_game_rewards = []
    log_delay_times = []
    log_start_time = time.time()
    
    try:
        for episode in range(episodes):
            env.reset()
                    
            done = False
            steps = 0 
            
            game_rewards = []
            
            # Game
            while (not done) and (steps < max_steps):
                next_states = env.get_next_states()
                
                best_action = agent.take_action(next_states)
                state, reward, done, info = env.step(best_action)
                
                # good = np.array_equal(next_states[best_action], state)
                # if not good:
                #     print(env.render_as_str())
                #     raise Exception("STATE MATCH FAIL")
                            
                agent.add_to_memory(state, reward, done, next_states[best_action])
                            
                game_rewards.append(reward)
                steps += 1
            average_game_rewards.append(np.mean(game_rewards))
            scores.append(info["score"])
            # Train
            if episode % train_every == 0:
                agent.train(batch_size=batch_size, epochs=epochs)
            if episode % log_every == 0:
                log_delay_times.append(time.time() - log_start_time)
                log_start_time = time.time()
                
                print("END OF GAME:", info)
                print(env.render_as_str())
                y_true, y_pred = env.value_function(), agent.predict_value(env.state_as_array())[0]
                print(f"{y_true=}, {y_pred=}")
            
                expected_round_time = np.mean(log_delay_times[-10:])
                rounds_left = (episodes - episode) / log_every
                
                print(f"Episode #{episode}, ({episode / episodes:.1%}). {agent.epsilon=} ({agent.name})")
                print(f"Estimated Time: Total={datetime.timedelta(seconds=int(expected_round_time * rounds_left))}, Round={datetime.timedelta(seconds=expected_round_time)}")
                avg_score = np.mean(scores[-log_every:])
                min_score = min(scores[-log_every:])
                max_score = max(scores[-log_every:])
                print(f"{avg_score = }, {min_score = }, {max_score = }")
                avg_reward = np.mean(average_game_rewards[-log_every:])
                min_reward = min(average_game_rewards[-log_every:])
                max_reward = max(average_game_rewards[-log_every:])
                print(f"{avg_reward = }, {min_reward = }, {max_reward = }")
                avg_score = np.mean(scores)
                avg_reward = np.mean(average_game_rewards)
                print(f"Overall: {avg_score = }, {avg_reward = }")
                
                print()
                
        avg_score = np.mean(scores)
        avg_reward = np.mean(average_game_rewards)    
        print(f"Final Overall: {avg_score = }, {avg_reward = }")
    except KeyboardInterrupt:
        print("Stopping...")
        
    agent.dump() 
if __name__ == "__main__":
    main()BOARD_WIDTH, BOARD_HEIGHT = 10, 20
SHAPE_QUEUE_SIZE = 3
AGENT_NAME = "tetris-ai"
from collections import deque
import numpy as np
import random
import pathlib
import sys
directory = pathlib.Path(__file__).parent.absolute()
sys.path.append(str(directory.parent.parent))
import neural_network as nn
class DQNAgent:
    def __init__(self, name: str, state_size: int, learning_rate: float = 0.01, mem_size=10000, discount: float = 0.95,
                 epsilon: float = 1, epsilon_min: float = 0, epsilon_stop_episode: int = 500,
                 replay_start_size: int = None):
        self.name = name
        # The size of our state (model input size)
        self.state_size = state_size
        # Our model
        layer_size = 2 ** 8  # 256
        self.network = nn.network.Network([
            nn.layers.Dense(state_size, layer_size),
            nn.activations.ReLU(),
            nn.layers.Dense(layer_size, layer_size),
            nn.activations.ReLU(),
            
            nn.layers.Dense(layer_size, layer_size),
            nn.activations.ReLU(),
            
            nn.layers.Dense(layer_size, 1),
            nn.activations.Linear(),
        ], loss=nn.losses.MSE())
         
        # Learning rate for training
        self.learning_rate = learning_rate
        
        # Replay Buffer
        self.memory = deque(maxlen=mem_size)
        
        # Exploration (probability of random values given) value at the start
        self.epsilon = epsilon
        # How important is the future rewards compared to the immediate ones [0,1]
        self.discount = discount
        
        # At what epsilon value the agent stops decrementing it
        self.epsilon_min = epsilon_min
        
        # How much is subtracted for the epsilon after the min is hit
        self.epsilon_decay = (self.epsilon - self.epsilon_min) / (epsilon_stop_episode)
        
        # Minimum memory size needed to train
        if replay_start_size is None: replay_start_size = mem_size // 2
        self.replay_start_size = replay_start_size
        
        # Location to dump/load model to/from
        self.save_file = str(directory / self.name)
    
    def add_to_memory(self, current_state: np.ndarray, reward: float, done: bool, next_state: np.ndarray) -> None:
        """Adds a play to the replay memory buffer"""
        self.memory.append((current_state, reward, done, next_state))
    def random_value(self) -> float:
        """Random score for a certain action"""
        return random.random()
    def predict_value(self, state: np.ndarray) -> float:
        """Predicts the score for a certain state"""
        return self.network.compute(state)[0]
    def best_state(self, states: list[np.ndarray]) -> np.ndarray:
        """Returns the best state for a given collection of state"""
        if (len(states) == 0): return None
         
        return max(states, key=self.predict_value)
    def take_action(self, next_states: dict[object, np.ndarray]) -> object:
        """Returns the best state for a given collection of state"""
        if random.random() <= self.epsilon: return random.choice(list(next_states.keys()))
        best_state = self.best_state(list(next_states.values()))
        for action, state in next_states.items():
            if np.array_equal(state, best_state):
                return action
    def train(self, batch_size = 512, epochs = 1) -> None:
        """Trains the agent"""
        if len(self.memory) >= self.replay_start_size and len(self.memory) >= batch_size:
            batch = random.sample(self.memory, batch_size)
            # Get the expected score for the next states, in batch (better performance)
            next_states = np.array([next_state for (state, reward, done, next_state) in batch])
            next_qs = [y[0] for y in self.network.compute(next_states)]
            x = np.empty((len(batch), self.state_size), dtype=np.float64)
            y = np.empty((len(batch), 1), dtype=np.float64)
            # Build xy structure to fit the model in batch (better performance)
            for i, (state, reward, done, next_state) in enumerate(batch):
                if not done:
                    # Partial Q formula
                    new_q = reward + self.discount * next_qs[i]
                else:
                    new_q = reward
                x[i] = (state)
                y[i, 0] = (new_q)
                
            # Fit the model to the given values
            self.network.train(x, y, batch_size=batch_size, epochs=epochs, learning_rate=self.learning_rate, logging=False)
            # Update the exploration variable
            self.epsilon = max(self.epsilon_min, self.epsilon - self.epsilon_decay)
    def dump(self):
        self.network.dump(self.save_file)
    def load(self):
        self.network.load(self.save_file)
        import json, time, pathlib
import pygame
import numpy as np
from tetris import Tetris, Move, TetrominoShape
import constants
from dqn_agent import DQNAgent
# Game Size
BOARD_SQUARES_ACROSS = constants.BOARD_WIDTH
BOARD_SQUARES_DOWN = constants.BOARD_HEIGHT
# Window sizes
SCREEN_WIDTH = 1000
SCREEN_HEIGHT = SCREEN_WIDTH / 1.618
TETRIS_SQUARE_SIZE = 25
GAME_WIDTH, GAME_HEIGHT = BOARD_SQUARES_ACROSS * TETRIS_SQUARE_SIZE, BOARD_SQUARES_DOWN * TETRIS_SQUARE_SIZE
GAME_X, GAME_Y = (SCREEN_WIDTH // 2 - GAME_WIDTH // 2, SCREEN_HEIGHT // 2 - GAME_HEIGHT // 2)
SIDE_PANEL_GAP = TETRIS_SQUARE_SIZE
SIDE_PANEL_WIDTH = TETRIS_SQUARE_SIZE * 7
SIDE_LEFT_X = GAME_X - SIDE_PANEL_WIDTH - SIDE_PANEL_GAP
SIDE_RIGHT_X = GAME_X + GAME_WIDTH + SIDE_PANEL_GAP
SIDE_PANEL_MARGIN = TETRIS_SQUARE_SIZE
OUTLINE_WIDTH = 3
# Other Window Data
WINDOW_NAME = "Tetris"
# Window colors
MAIN_COLOR = "white"
BACKGROUND_COLOR = "black"
SECONDARY_COLOR = (50, 50, 50)
# Game speed
FPS = 30
KEY_REPEAT_DELAY = (170 / 1000) * FPS
KEY_REPEAT_INTERVAL = (50 / 1000) * FPS
# Path
PATH = pathlib.Path(__file__).parent
MEDIA_PATH = PATH / "assets"
SHAPE_IMAGES: dict[TetrominoShape, pygame.Surface] = {
    shape: pygame.image.load(MEDIA_PATH / "normal-tetromino" / f"{shape.get_name()}.png") for shape in TetrominoShape.ALL_SHAPES
SHAPE_GHOST_IMAGES: dict[TetrominoShape, pygame.Surface] = {
    shape: pygame.image.load(MEDIA_PATH / "ghost-tetromino" / f"{shape.get_name()}.png") for shape in TetrominoShape.ALL_SHAPES
HIGH_SCORE_STORAGE_PATH = PATH / "highScore.json"
BLANK_SURFACE = pygame.Surface((0, 0))
# Game rules
PIECE_QUEUE_SIZE = 3
SHOW_GHOST_PEACES = True
def blit_with_outline(screen: pygame.Surface, source: pygame.Surface, dest: tuple[int, int]) -> None:
    line_width = OUTLINE_WIDTH
    outline_color = MAIN_COLOR
    x, y = dest
    width, height = source.get_width(), source.get_height()
    pygame.draw.rect(screen, outline_color, pygame.Rect(x - line_width, y - line_width, width + line_width * 2, height + line_width * 2), width = line_width)  
    screen.blit(source, dest)
def main() -> None:
    
    pygame.init()
    pygame.mixer.init()
     
    pygame.mixer.music.load(MEDIA_PATH / "tetris.mp3") 
    pygame.mixer.music.play(-1, 0, 1000 * 10)
    game = Tetris(
        width=BOARD_SQUARES_ACROSS, height=BOARD_SQUARES_DOWN, shape_queue_size=constants.SHAPE_QUEUE_SIZE,
        FPS=FPS,
        enable_wall_kick=True, enable_hold=True
    )
    
    agent = DQNAgent(constants.AGENT_NAME, game.state_as_array().size, epsilon=0)
    try: 
        agent.load()
    except FileNotFoundError:
        agent = None
    
    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))
    pygame.display.set_caption(WINDOW_NAME)
        
    button_size = TETRIS_SQUARE_SIZE * 2
    
    pause_button = ToggleButton(screen, (262 - button_size / 2 - 5, 483),
                                pygame.image.load(MEDIA_PATH / "play.png"),
                                pygame.image.load(MEDIA_PATH / "pause.png"),
                                button_size)
    mute_button = ToggleButton(screen, (262 + button_size / 2 + 5, 483),
                                pygame.image.load(MEDIA_PATH / "mute_sound.png"),
                                pygame.image.load(MEDIA_PATH / "play_sound.png"),
                                button_size)
        
    clock = pygame.time.Clock()
        
    title_font = pygame.font.SysFont("Monospace", 50, True, False)
    paused_text = title_font.render("PAUSED", True, MAIN_COLOR)
    
    font = pygame.font.SysFont("Berlin Sans FB", 22, False, False)
        
    pressing_down_arrow =  False
    left_down_clock = right_down_clock = None
    
    has_quit_game = False
    game_going = True
    
    used_ai_control = using_ai_control = False
    
    fps_speed_level = 0
    fps_change_percent = 10
        
    while game_going and (not has_quit_game):                
        screen.fill(BACKGROUND_COLOR)
        
        prefix = ("(AI)" if using_ai_control else "")
        title = title_font.render(WINDOW_NAME + prefix, True, MAIN_COLOR) 
        screen.blit(title, (SCREEN_WIDTH // 2 - title.get_width() // 2, 0))
         
        moves = []
        
        left_click = up = down = False
        
        for event in pygame.event.get():
            if event.type == pygame.QUIT:           has_quit_game = True
            elif event.type == pygame.KEYDOWN:
                if event.key == pygame.K_ESCAPE:    game_going = False
                if event.key == pygame.K_UP:        up = True; moves.append(Move.SPIN)
                if event.key == pygame.K_SPACE:     moves.append(Move.HARD_DROP)
                if event.key == pygame.K_c:         moves.append(Move.HOLD)
                if event.key == pygame.K_p:         pause_button.toggle_state()
                if event.key == pygame.K_m:         mute_button.toggle_state()
                if event.key == pygame.K_a:         using_ai_control = not using_ai_control
                if event.key == pygame.K_LEFT:
                    moves.append(Move.LEFT)
                    left_down_clock = KEY_REPEAT_DELAY
                if event.key == pygame.K_RIGHT:      
                    right_down_clock = KEY_REPEAT_DELAY
                    moves.append(Move.RIGHT)
                if event.key == pygame.K_DOWN:      down = pressing_down_arrow = True
            elif event.type == pygame.KEYUP:
                if event.key == pygame.K_DOWN:      pressing_down_arrow = False
                if event.key == pygame.K_LEFT:      left_down_clock = None
                if event.key == pygame.K_RIGHT:     right_down_clock = None
            elif event.type == pygame.MOUSEBUTTONDOWN and event.button == 1:
                left_click = True 
                
        mouse_pos = pygame.mouse.get_pos()
        for button in ToggleButton.all_buttons:
            button.update(mouse_pos, mouse_down = left_click)
        
        if left_down_clock is not None:
            left_down_clock -= 1
            if left_down_clock <= 0:
                moves.append(Move.LEFT)
                left_down_clock = KEY_REPEAT_INTERVAL
        if right_down_clock is not None:
            right_down_clock -= 1
            if right_down_clock <= 0:
                moves.append(Move.RIGHT)
                right_down_clock = KEY_REPEAT_INTERVAL
        
        if pressing_down_arrow: moves.append(Move.SOFT_DROP)   
        
        if using_ai_control:            
            moves.clear()
            
            if up: fps_speed_level += 1
            if down: fps_speed_level -= 1 
            
            used_ai_control = True
            
            if agent is not None:
                next_states = game.get_next_states()
                
                best_action = agent.take_action(next_states)
                
                moves.extend(best_action)
        else:
            fps_speed_level = 0
        
        if (not pause_button.get_state()) or (game.frame < 1):    
            state, reward, done, info = game.step(moves)
                
        if done: game_going = False
         
        should_pause = (pause_button.get_state() or mute_button.get_state())
        is_playing = pygame.mixer.music.get_busy()
        if should_pause and is_playing: pygame.mixer.music.pause()
        if not (should_pause or is_playing): pygame.mixer.music.unpause()
        
        tetris_board_surface = render_game(
            game,
            block_size=TETRIS_SQUARE_SIZE,
            ghost_block=SHOW_GHOST_PEACES
        )
        
        blit_with_outline(screen, tetris_board_surface, (GAME_X, GAME_Y))
                 
        minutes, seconds = divmod(info["frame"] / FPS, 60)
        
        display_info = {
            **info,
            "fps": round(clock.get_fps(), 3),
            "time": f"{minutes:.0f}:{seconds:0>2.0f}",
            "reward": round(reward, 3),
            "ai_reward": f"{agent.predict_value(state)[0]:.5f}" if agent else None,
        }
        
        info_side_panel = render_info_panel(
            {key: display_info[key] for key in ["score", "level", "lines", "time"]},
            font=font, width=SIDE_PANEL_WIDTH, margin=SIDE_PANEL_MARGIN
        )
        
        blit_with_outline(screen, info_side_panel, (SIDE_LEFT_X, GAME_Y))
        
        ai_info_side_panel = render_info_panel(
            {key: display_info[key] for key in ["reward", "ai_reward"]},
            font=font, width=SIDE_PANEL_WIDTH - (SIDE_PANEL_MARGIN * 2), margin=(0, SIDE_PANEL_MARGIN)
        )
        fps_percent = 1 + (fps_speed_level * (fps_change_percent / 100))
        fps = FPS * fps_percent
        fps_panel = render_info_panel(
            {"fps": format(clock.get_fps(), ".2f"), "speed": format(fps_percent, ".0%")},
            font=font, width=SIDE_PANEL_WIDTH - (SIDE_PANEL_MARGIN * 2), margin=(0, SIDE_PANEL_MARGIN)
        )
        
        if used_ai_control:
            blit_with_outline(screen, ai_info_side_panel, (SIDE_LEFT_X - SIDE_PANEL_WIDTH + SIDE_PANEL_MARGIN, GAME_Y))
            blit_with_outline(screen, fps_panel, (SIDE_LEFT_X - SIDE_PANEL_WIDTH + SIDE_PANEL_MARGIN, GAME_Y + SIDE_PANEL_GAP + ai_info_side_panel.get_height()))
        next_side_panel = render_info_panel(
            {"next": render_shapes(info["piece_queue"], TETRIS_SQUARE_SIZE)},
            font=font, width=SIDE_PANEL_WIDTH, margin=SIDE_PANEL_MARGIN
        )
        blit_with_outline(screen, next_side_panel, (SIDE_RIGHT_X, GAME_Y))
        
        held_side_bar = render_info_panel(
            {"held": render_shapes([info["held"]], TETRIS_SQUARE_SIZE)},
            font=font, width=SIDE_PANEL_WIDTH, margin=SIDE_PANEL_MARGIN
        )
        
        blit_with_outline(screen, held_side_bar, (SIDE_RIGHT_X, GAME_Y + GAME_HEIGHT - held_side_bar.get_height()))
        
        control_side_bar = render_info_panel(
            {"control": render_shapes([None], TETRIS_SQUARE_SIZE)},
            font=font, width=SIDE_PANEL_WIDTH, margin=SIDE_PANEL_MARGIN
        )
        blit_with_outline(screen, control_side_bar, (SIDE_LEFT_X, GAME_Y + GAME_HEIGHT - control_side_bar.get_height()))
        pause_button.draw()
        mute_button.draw()
         
        if pause_button.get_state():
            screen.blit(paused_text, (SCREEN_WIDTH // 2 - paused_text.get_width() // 2, SCREEN_HEIGHT // 2 - paused_text.get_height() // 2))
                    
        pygame.display.flip()
        clock.tick(fps)
    
    if not has_quit_game:
        waiting_for_key = True
        
        try:
            with open(MEDIA_PATH.parent / HIGH_SCORE_STORAGE_PATH, "r") as file:
                high_score = json.load(file)
        except FileNotFoundError:
            high_score = {}
        
        if info["score"] > high_score.get("score", 0):
            high_score["score"] = info["score"]
            high_score["ai"] = used_ai_control
            high_score["ctime"] = time.ctime()
            high_score["time"] = time.time()
            
            with open(MEDIA_PATH.parent / HIGH_SCORE_STORAGE_PATH, "w") as file:
                json.dump(high_score, file)
            
        game_over_bar = render_info_panel(
            {"Game Over": BLANK_SURFACE, "score": info["score"], "best": high_score["score"], "Again?": "Space Key"},
            font=font, width=(8 * TETRIS_SQUARE_SIZE), margin=SIDE_PANEL_MARGIN
        )
        
        frame = 0
        wait_seconds = 1
        draw_on_frame = (FPS * wait_seconds)
        
        pygame.mixer.music.fadeout(wait_seconds * 1000)
         
        while waiting_for_key and (not has_quit_game):
            frame += 1
            for event in pygame.event.get():
                if event.type == pygame.QUIT: has_quit_game = True
                elif frame > draw_on_frame and event.type == pygame.KEYDOWN and event.key == pygame.K_SPACE: waiting_for_key = False
            if frame > draw_on_frame:
                blit_with_outline(screen, game_over_bar, (GAME_X + GAME_WIDTH // 2 - game_over_bar.get_width() // 2, GAME_Y + GAME_HEIGHT // 2 - game_over_bar.get_height() // 2))
                pygame.display.flip()
            clock.tick(FPS)
    if has_quit_game: pygame.quit()
    else: main()
    
def draw_tetromino_block(screen: pygame.Surface, block_size: int, row: int, col: int, shape: TetrominoShape, ghost = False):
    image = (SHAPE_GHOST_IMAGES if ghost else SHAPE_IMAGES)[shape]
    if image.get_width() != block_size: image = pygame.transform.scale(image, (block_size, block_size))
    screen.blit(image, pygame.Rect(col * block_size, row * block_size, block_size, block_size))
def render_game(game: Tetris, block_size: int = 25, ghost_block = True) -> tuple[pygame.Surface, list[pygame.Surface]]:    
    screen = pygame.Surface((game.width * block_size, game.height * block_size))
                        
    screen.fill(BACKGROUND_COLOR)
    
    for col in range(1, game.width):
        pygame.draw.line(screen, SECONDARY_COLOR, (block_size * col, 0), (block_size * col, block_size * game.height), width=1)
    for row in range(1, game.height):
        pygame.draw.line(screen, SECONDARY_COLOR, (0, block_size * row), (block_size * game.width, block_size * row), width=1)
    for value, (row, col) in game:
        if value: draw_tetromino_block(screen, block_size, row, col, TetrominoShape.SHAPE_ID_MAP[value])
            
    for value, (row, col) in game.current_tetromino:
        if value: draw_tetromino_block(screen, block_size, row, col, game.current_tetromino.shape)
        
    if ghost_block:   
        real_y = game.current_tetromino.y
        
        while not game.intersects():
            game.current_tetromino.y += 1
        game.current_tetromino.y -= 1
    
        for value, (row, col) in game.current_tetromino:
            if value: draw_tetromino_block(screen, block_size, row, col, game.current_tetromino.shape, ghost=True)
        
        game.current_tetromino.y = real_y
        
    return screen
def render_shape(shape: TetrominoShape, block_size: int) -> pygame.Surface:
    if shape is None: return BLANK_SURFACE 
    
    grid = shape.get_trimmed_grid()
    height, width = grid.shape
        
    shape_render = pygame.Surface((width * block_size, height * block_size))
    
    for row in range(height):
        for col in range(width):
            if grid[row, col]: draw_tetromino_block(shape_render, block_size, row, col, shape)
    
    return shape_render
_max_trimmed_height = max(shape.get_trimmed_grid().shape[0] for shape in TetrominoShape.ALL_SHAPES)
def render_shapes(shape_queue: list[TetrominoShape], block_size: int) -> pygame.Surface:
    rendered_shapes = [render_shape(shape, block_size) for shape in shape_queue]
    max_trimmed_height = _max_trimmed_height * block_size
    rendered_queue = pygame.Surface((
        max(shape.get_width() for shape in rendered_shapes),
        block_size + sum(max_trimmed_height + block_size for shape in rendered_shapes)
    ))
     
    y = block_size
    
    center_x = rendered_queue.get_width() // 2
    center_y = max_trimmed_height // 2
    
    for shape in rendered_shapes:
        rendered_queue.blit(shape, (center_x - shape.get_width() // 2, y + center_y - shape.get_height() // 2))
        y += max_trimmed_height + block_size
    
    return rendered_queue
    
def render_section(title: str, content: pygame.Surface, font: pygame.font.Font, width: int) -> pygame.Surface:
    title_render = font.render(title, True, MAIN_COLOR)
    
    title_area_height = title_render.get_height()
    content_area_height = content.get_height() 
    
    section = pygame.Surface((width, title_area_height + content_area_height))
    
    pygame.draw.rect(section, SECONDARY_COLOR, pygame.Rect((0, 0), (width, title_area_height)))
    pygame.draw.rect(section, BACKGROUND_COLOR, pygame.Rect((0, title_area_height), (width, content_area_height)))
    
    section.blit(title_render, (
        section.get_width() // 2 - title_render.get_width() // 2,
        title_area_height // 2 - title_render.get_height() // 2))
    
    section.blit(content, (
        section.get_width() // 2 - content.get_width() // 2,
        title_area_height + content_area_height // 2 - content.get_height() // 2))
    
    return section
    
def render_info_panel(data: dict[str, pygame.Surface], font: pygame.font.Font, width: int, margin: int | tuple[int, int]):
    data = {key.upper().replace("_", " "): (value if isinstance(value, pygame.Surface) else font.render(str(value), True, MAIN_COLOR)) for key, value in data.items()}
        
    try: x_margin, y_margin = margin
    except TypeError: x_margin = y_margin = margin
    
    height = y_margin + sum(font.get_height() + section.get_height() + y_margin for section in data.values())
    panel = pygame.Surface((width, height))
        
    panel.fill(SECONDARY_COLOR)
    
    section_y = y_margin
    section_width = width - x_margin * 2
    
    for title, content in data.items():
        section = render_section(title, content, font, section_width)
        panel.blit(section, (x_margin, section_y))
        section_y += section.get_height() + y_margin
        
    return panel
class ToggleButton:
    all_buttons: list["ToggleButton"] = []
    
    def __init__(self, screen: pygame.Surface, position: tuple[int, int], enable: pygame.Surface, disable: pygame.Surface, size: int) -> None:
        self.x, self.y = position
        self.size = size
        
        self.radius_squared = (self.size / 2) ** 2
                
        self.screen = screen
        
        self.enable = pygame.transform.scale(enable, (self.size, self.size))
        self.disable = pygame.transform.scale(disable, (self.size, self.size))
        
        self.state = self.is_clicked = self.is_hovered = False
        
        ToggleButton.all_buttons.append(self)
    
    def is_over(self, pos: tuple[int, int]) -> bool:
        return pygame.Vector2(pos).distance_squared_to((self.x, self.y)) <= self.radius_squared
                
    def update(self, mouse_pos: tuple[int, int], mouse_down: bool = False) -> None:
        
        self.is_hovered = self.is_over(mouse_pos)
        self.is_clicked = self.is_hovered and mouse_down
         
        if self.is_clicked: self.toggle_state()
        
    def draw(self) -> None:
        image = self.enable if self.state else self.disable
        image = pygame.transform.scale_by(image, 1 + (-0.2 if self.is_clicked else 0) + (0.1 if self.is_hovered else 0))
        
        self.screen.blit(image, (self.x - image.get_width() // 2, self.y - image.get_height() // 2))
        # blit_with_outline(self.screen, image, (self.x - image.get_width() // 2, self.y - image.get_height() // 2))
        # pygame.draw.circle(self.screen, "red", (self.x, self.y), 10)
    
    def toggle_state(self) -> None:
        self.state = not self.state
        
    def get_state(self) -> bool: return self.state
if __name__ == "__main__":
    print("""\033[32m
[][][][][] [][][][] [][][][][] [][][][]  [][][]   [][][]  
    []     []           []     []     []   []   []      [] 
    []     []           []     []     []   []   []       
    []     [][][]       []     [][][][]    []     [][][]  
    []     []           []     []   []     []           [] 
    []     []           []     []    []    []   []      [] 
    []     [][][][]     []     []     [] [][][]   [][][]          
          \033[0m""")
    
    print(f"\033[1m{'Button':<12} Action\033[0m")
    for key, control in {
        "up arrow": "rotate",
        "left arrow": "left",
        "right arrow": "right",
        "down arrow": "soft drop",
        "space": "hard drop",
        "c": "hold",
        "esc": "quit",
        "p": "pause",
        "m": "mute",
        "a": "enable ai",
    }.items():
        print(f"{key.title():<12} {control.upper()}\033[0m")
    
    main()import random
import enum
import numpy as np
from .shapes import TetrominoShape
class Move(enum.Enum):
    SPIN = enum.auto()
    LEFT = enum.auto()
    RIGHT = enum.auto()
    SOFT_DROP = enum.auto()
    HARD_DROP = enum.auto()
    HOLD = enum.auto()
    
    QUIT = enum.auto()
class Tetromino:
    WALL_BOUNCING = True
    
    def __init__(self, x: int, y: int, shape: TetrominoShape, orientation: int = 0) -> None:
        self.x = x
        self.y = y
        
        self.shape = shape
        
        self.orientation = orientation % len(self.shape.rotations)
    
    def get_height(self) -> int: return self.get_grid().shape[1]
        
    def get_width(self) -> int: return self.get_grid().shape[0]
    def get_color(self) -> tuple[int, int, int] | str: return self.shape.get_color()
    
    def get_name(self) -> str: return self.shape.get_name()
    
    def get_id(self) -> int: return self.shape.get_id()
    def get_grid(self) -> np.ndarray: return self.shape.get_grid(self.orientation)
     
    def rotate(self) -> None: self.orientation = (self.orientation + 1) % len(self.shape.rotations)            
    def __iter__(self):
        for row in range(self.get_height()):
            for col in range(self.get_width()):
                yield (self.get_grid()[row][col], (self.y + row, self.x + col))
    
    def __str__(self) -> str:
        return f"{self.__class__.__name__}(x={self.x}, y={self.y}, shape={self.shape}, orientation={self.orientation})"
class Tetris:
    DEFAULT_FPS = 60
    
    def __init__(
        self, width: int, height: int, FPS: int = DEFAULT_FPS,
        enable_wall_kick = True, shape_queue_size: int = None, enable_hold = True) -> None:
        self.width, self.height = width, height
        
        self.fps = FPS
        
        self.enable_wall_kick = enable_wall_kick
        
        if shape_queue_size is None: shape_queue_size = 0
        self.shape_queue_size = shape_queue_size
        
        self.done: bool
        self.frame: int
        self.score: int
        self.lines: int
        self.level: int
        
        self.block_drop_interval: int
        
        self.current_tetromino: Tetromino
        
        self.held_shape: TetrominoShape
        self.can_swap: bool
        
        self._shape_queue: list[TetrominoShape]
        
        self.enable_hold = enable_hold
        
        self.fps_scale = self.fps / self.DEFAULT_FPS
        
        self.reset()
        self._create_inputs_cache()
    def reset(self) -> None:
        self.grid = np.zeros((self.height, self.width))
        
        self._shape_queue = []
        self.fill_piece_queue()
        
        self.frame = self.score = self.lines = self.level = 0
        self.block_drop_interval = self.DEFAULT_FPS * self.fps_scale
        
        self.done = False
        self.held_shape = None
         
        self.new_figure()
        
    def fill_piece_queue(self):
        while len(self._shape_queue) < self.shape_queue_size + 1:
            shape = random.choice(TetrominoShape.ALL_SHAPES)
            self._shape_queue.append(shape)
    def get_current_figure(self) -> Tetromino:
        return self.current_tetromino
    
    @property
    def shape_queue(self):
        return self._shape_queue[:-1]
    def new_figure(self) -> None:
        self.can_swap = True
        
        shape = self._shape_queue.pop(0)
        
        self.current_tetromino = Tetromino(
            self.width // 2 - shape.get_width() // 2, 0,
            shape
        )
        
        self.fill_piece_queue()
    
    def get_state(self) -> tuple:
        return (
            self.grid.copy(), self._shape_queue.copy(), self.held_shape, self.can_swap,
            self.current_tetromino, (self.current_tetromino.x, self.current_tetromino.y, self.current_tetromino.orientation),
            self.frame, self.score, self.lines, self.level, self.block_drop_interval, self.done,
        )
    
    def set_state(self, data: tuple) -> None:
        (
            self.grid, self._shape_queue, self.held_shape, self.can_swap,
            self.current_tetromino, (self.current_tetromino.x, self.current_tetromino.y, self.current_tetromino.orientation),
            self.frame, self.score, self.lines, self.level, self.block_drop_interval, self.done,
        ) = data
                
    def hold(self) -> None:
        if not (self.enable_hold and self.can_swap): return
        
        starting_current = self.current_tetromino
        if self.held_shape: self._shape_queue.insert(0, self.held_shape)
        
        self.new_figure()
        
        self.can_swap = False
        self.held_shape = starting_current.shape
    def intersects(self) -> bool:
        for value, (row, col) in self.current_tetromino:
            if value and ( 
                row >= self.height or row < 0 or col >= self.width or col < 0 or
                self.grid[row][col] != 0
            ):
                return True
        return False
        
    def find_full_lines(self) -> list[int]:
        return [i for i, row in enumerate(self.grid) if all(row)]
    def remove_full_lines(self, lines: list[int]) -> None:
        for line in lines:
            self.grid[1:line + 1, :] = self.grid[:line, :]
            self.grid[0, :] = 0
    
    def hard_drop(self) -> None:
        
        while not self.intersects():
            self.score += 2
            self.current_tetromino.y += 1
            
        self.current_tetromino.y -= 1
        self.score -= 2
        
        self.freeze()
    def soft_drop(self):
        self.score += 1
        self.current_tetromino.y += 1
        
        if self.intersects():
            self.current_tetromino.y -= 1
            self.score -= 1
            
    def gravity_drop(self) -> None:
        self.current_tetromino.y += 1
        
        if self.intersects():
            self.current_tetromino.y -= 1
            self.freeze()
    def freeze(self) -> bool:
        for value, (row, col) in self.current_tetromino:
            if value: self.grid[row][col] = self.current_tetromino.get_id()
        
        full_line_indexes = self.find_full_lines()
        self.remove_full_lines(full_line_indexes)
        self.new_figure()
        num_of_lines = len(full_line_indexes)
        
        scores = [0, 40, 100, 300, 1200]
        
        # Optimization
        if num_of_lines > 0:
            self.lines += num_of_lines
            self.score += scores[num_of_lines] * (self.level + 1)
            self.level = (self.lines // 10)
            if self.level < 11: block_drop_interval = 60 - self.level * 5
            elif self.level < 12: block_drop_interval = 9
            elif self.level < 13: block_drop_interval = 8
            elif self.level < 15: block_drop_interval = 7
            elif self.level < 17: block_drop_interval = 6
            elif self.level < 20: block_drop_interval = 5
            elif self.level < 24: block_drop_interval = 4
            elif self.level < 29: block_drop_interval = 3
            elif self.level < 30: block_drop_interval = 3
            else: block_drop_interval = 1
            
            self.block_drop_interval = max(int(block_drop_interval * self.fps_scale), 1)
        
        self.done = self.intersects() 
        
    def change_x(self, dx: int) -> None:
        old_x = self.current_tetromino.x
        self.current_tetromino.x += dx
        if self.intersects():
            self.current_tetromino.x = old_x
    def rotate(self) -> None:
        positions_to_try = [(0, 0)]
        
        if self.enable_wall_kick:
            positions_to_try.extend([(1, 0), (-1, 0)])
        
        for (dx, dy) in positions_to_try:
            self.current_tetromino.x += dx
            self.current_tetromino.y += dy
            
            old_orientation = self.current_tetromino.orientation
            self.current_tetromino.rotate()      
            if self.intersects(): self.current_tetromino.orientation = old_orientation
            else: return
                
            self.current_tetromino.x -= dx
            self.current_tetromino.y -= dy
                
    def step(self, moves: list[Move], quick_return = False) -> tuple[np.ndarray, float, bool, dict]:
        self.frame += 1
        
        soft_drop = False
        for move in moves:
            match move:
                case Move.QUIT: self.done = True
                case Move.SPIN: self.rotate()
                case Move.LEFT: self.change_x(-1)
                case Move.RIGHT: self.change_x(+1)
                case Move.HOLD: self.hold()
                case Move.HARD_DROP: self.hard_drop()
                case Move.SOFT_DROP: soft_drop = True
                case None: pass
         
        is_drop_frame = self.frame % self.block_drop_interval == 0
        is_soft_drop_frame = soft_drop and self.frame % self.fps_scale == 0
            
        if is_drop_frame: self.gravity_drop()
        elif is_soft_drop_frame: self.soft_drop()
        
        if quick_return:
            return self.state_as_array(), None, None, None
        
        reward = self.value_function()
                
        info = {
            "score": self.score,
            "lines": self.lines,
            "level": self.level,
            "held": self.held_shape,
            "piece_queue": self.shape_queue,
            "frame": self.frame,
        }
        
        return self.state_as_array(), reward, self.done, info
        
    def render_as_str(self, block_width = 2, full_block = True) -> str:
        
        full = "[" + " " * (block_width - 2) + "]"
        
        if full_block: full = "" * block_width
        empty = " " * (block_width - 1) + "."
        line_padding_left = "!"
        line_padding_right = "!"
        line_padding_width = 3  # Angle brackets have space built in
        lines = []
        for row_index, row in enumerate(self.grid):
            lines.append(
                line_padding_left
                + "".join([full if (tile or (1, (row_index, col_index)) in self.current_tetromino) else empty for col_index, tile in enumerate(row)])
                + line_padding_right
            )
        bottom1 = "="
        lines.append(
            line_padding_left + bottom1 * (self.width * block_width // len(bottom1)) + line_padding_right
        )
        bottom2 = "\\/"
        lines.append(
            " " * line_padding_width
            + (bottom2 * (self.width * block_width // len(bottom2)))
            + " " * line_padding_width
        )
        return "\n".join(lines)
    def __str__(self) -> str:
        return self.render_as_str()
    
    def __iter__(self):
        for row in range(self.height):
            for col in range(self.width):
                yield (self.grid[row][col], (row, col))
    
    # Ai related methods
    
    def _create_inputs_cache(self):
        self._piece_to_index = dict(((b, a) for (a, b) in enumerate(TetrominoShape.ALL_SHAPES)))
        self._one_hot_shapes = np.eye(len(TetrominoShape.ALL_SHAPES), dtype=np.float64)
        self._one_hot_x = np.eye(self.width, dtype=np.float64)
        self._one_hot_y = np.eye(self.height, dtype=np.float64) 
        self._one_hot_rotations = np.eye(TetrominoShape.MAX_ROTATIONS, dtype=np.float64)
        
    def state_as_array(self) -> np.ndarray:
        
        state = self.get_state()
        self.hard_drop()
        hard_drop_grid = (self.grid > 0).flatten()
        self.set_state(state)
        
        return np.concatenate([
            (self.grid > 0).flatten(), #  board
            hard_drop_grid, # board after hard drop (ghost block like feature)
            self._one_hot_shapes[self._piece_to_index[self.current_tetromino.shape]], # piece type
            self._one_hot_x[self.current_tetromino.x], # x
            self._one_hot_y[self.current_tetromino.y], # y
            self._one_hot_rotations[self.current_tetromino.orientation], # rotation
            self._one_hot_shapes[self._piece_to_index[self._shape_queue[0]]], # next piece type
        ], dtype=np.float64)
        
    def value_function(self) -> float:        
        heights = self._get_column_heights()
        
        return 1 - (
            + 0.5 * (self._get_number_of_holes() / self.width)
            + 0.3 * (np.max(heights) / self.height)
            + 0.2 * (np.mean(heights) / self.height)
            + 0.1 * (self._heights_bumpiness(heights) / self.height)
        ) * 2 - (self.done * 5)
    
    _next_state_move = {None: 1, Move.LEFT: 5, Move.RIGHT: 5, Move.SPIN: 4}
    def get_next_states(self) -> dict[Move, np.ndarray]:
        output = {}
        
        start_state_array = self.state_as_array()
        
        for move, repeat in self._next_state_move.items():
            for i in range(repeat):
                moves = tuple([move] * (i + 1))
                state = self.get_state()
                state_array, _, _, _ = self.step(moves, quick_return=True)
                if (move is None) or not np.array_equal(state_array, start_state_array): output[moves] = state_array
                self.set_state(state)
        
        return output
    
    def _get_number_of_holes(self) -> int:
        holes = 0
        for col in self.grid.T:
            has_seen_block = False
            for value in col:
                if (not has_seen_block and value): has_seen_block = True
                holes += (has_seen_block) and value == 0
        
        return holes
    
    def _get_column_heights(self) -> np.ndarray[int] | int:
        mask = self.grid != 0
        return self.height - np.where(mask.any(axis=0), mask.argmax(axis=0), self.height)
    
    def _heights_bumpiness(self, heights: np.ndarray[int]) -> int:
        total_bumpiness = 0
        for i, height in enumerate(heights[:-1]):
            height_difference = height - heights[i + 1]
            total_bumpiness += abs(height_difference)
        return total_bumpinessimport numpy as np
def rotate(shape):
    return np.flip(np.rot90(shape))
class TetrominoShape:
    MAX_ROTATIONS = 4
    
    ALL_SHAPES: list["TetrominoShape"] = []
    SHAPE_ID_MAP: dict[int, "TetrominoShape"] = {}
    def __init__(self, name: str, shape: list[list[int]] | np.ndarray, color: str | tuple[int, int, int] = "white") -> None:
        self.name = name
        self.color = color
        self.id = len(self.ALL_SHAPES) + 1
        
        TetrominoShape.ALL_SHAPES.append(self)
        TetrominoShape.SHAPE_ID_MAP[self.id] = self
        shape = np.array(shape, dtype=int)
        self.rotations: list[np.ndarray] = []
        for i in range(TetrominoShape.MAX_ROTATIONS):
            self.rotations.append(shape)
            shape = rotate(shape)
            if np.array_equal(shape, self.rotations[0]):
                break
    def get_name(self) -> str: return self.name
    def get_color(self) -> str | tuple[int, int, int]: return self.color
    def get_id(self) -> int: return self.id
    def get_num_of_rotations(self) -> int: return len(self.rotations)
    
    def get_grid(self, rotation = 0) -> np.ndarray: return self.rotations[rotation]
    
    def get_width(self, rotation = 0) -> int: return self.get_grid(rotation).shape[1]
    
    def get_height(self, rotation = 0) -> int: return self.get_grid(rotation).shape[0]
    def get_trimmed_grid(self, rotation = 0):
        grid = self.get_grid(rotation) 
        
        zeros = np.where(grid != 0)
        grid = grid[min(zeros[0]) : max(zeros[0]) + 1, min(zeros[1]) : max(zeros[1]) + 1]
        
        return grid
        
    def __str__(self) -> str:
        return f"{self.__class__.__name__}({self.name}, {self.rotations[0]})"
TetrominoShape("I", [
    [0, 0, 0, 0],
    [1, 1, 1, 1],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
], (0, 240, 240)),
TetrominoShape("O", [
    [1, 1],
    [1, 1],
], (240, 240, 0)),
TetrominoShape("L", [
    [0, 0, 1],
    [1, 1, 1],
    [0, 0, 0],
], (240, 160, 0)),
TetrominoShape("J", [
    [1, 0, 0],
    [1, 1, 1],
    [0, 0, 0],
], (0, 0, 240)),
TetrominoShape("T", [
    [0, 1, 0],
    [1, 1, 1],
    [0, 0, 0],
], (160, 0, 240)),
TetrominoShape("Z", [
    [1, 1, 0],
    [0, 1, 1],
    [0, 0, 0],
], (240, 0, 0)),
TetrominoShape("S", [
    [0, 1, 1],
    [1, 1, 0],
    [0, 0, 0],
], (0, 240, 0)),
def main() -> None:
    states = [" .", ""]
    for shape in TetrominoShape.ALL_SHAPES:
        print(shape.name + ": ")
        for i, orientation in enumerate(shape.rotations):
            print()
            print("\n".join(
                "".join(states[value] for value in row) for row in orientation
            ))
        print()
if __name__ == "__main__":
    main()
from .game_board import Tetris, Move
from .shapes import TetrominoShape
__all__ = [Tetris, TetrominoShape, Move]
# Grid: a 2d numpy array
# Shape: A type of tetromino (I, J, L, etc)
# Tetromino: An actual tetromino that has a location and orientation
# Rotations: A list of all orientation as gridsfrom model import BasicModel
from player import PygamePlayer
from display import PygameDisplay
import pygame
clock = pygame.time.Clock()
model = BasicModel()
player = PygamePlayer(PygamePlayer.DEFAULT_BINDINGS)
display = PygameDisplay({})
model.reset()
while True:
    actions = player.get_actions()
    state = model.update(actions)
    display.update(state)
    if pygame.event.get(pygame.QUIT):
        break
    clock.tick(60)
import enum as _enum
class Action(_enum.Enum):
    SPIN = _enum.auto()
    LEFT = _enum.auto()
    RIGHT = _enum.auto()
    SOFT_DROP = _enum.auto()
    HARD_DROP = _enum.auto()
    HOLD = _enum.auto()
import dataclasses
import numpy as np
@dataclasses.dataclass(slots=True)
class State:
    board: np.ndarray
    current_tetromino_board: np.ndarray
    current_tetromino_percent_placed: float
    ghost_tetromino_board: np.ndarray
    held_tetromino: np.ndarray
    can_use_held_tetromino: bool
    tetromino_queue: list[np.ndarray]
    info: dict[str, str]
    has_lost: bool
    board_null_value: intimport numpy as np
from game_state import State
from .display import Display
class ConsoleDisplay(Display):
    def __init__(self, row_template_str="[%s]", full_tile_template_str=" %s", empty_tile_str="  ") -> None:
        self.row_template_str = row_template_str
        self.full_tile_template_str = full_tile_template_str
        self.empty_tile_str = empty_tile_str
    
    def update(self, state: State) -> None:
        print(", ".join(f"{key}: {value}" for key, value in state.info.items()))
        combined_board = combined_board = np.where(
            state.current_tetromino_board != state.board_null_value,
            state.current_tetromino_board, state.board)
        print(self.get_grid_string(combined_board, state.board_null_value))
        
    def get_grid_string(
        self, grid: np.ndarray, null_value: int
    ) -> str:
        return "\n".join(
            self.row_template_str
            % (
                "".join(
                    (
                        self.full_tile_template_str % item
                        if (item != null_value)
                        else self.empty_tile_str
                    )
                    for item in row
                )
            )
            for row in grid
        )from game_state import State
class Display:
    def update(self, state: State) -> None:
        passimport pathlib
import numpy as np
import pygame
from game_state import State
from .display import Display
from .tetris_ui import ToggleButton, TetrisRenderer, TetrominoTiles, GridContext
def gray_scale(surface: pygame.Surface) -> pygame.Surface:
    array = pygame.surfarray.array3d(surface)
    # luminosity filter
    averages = [
        [(r * 0.298 + g * 0.587 + b * 0.114) for (r, g, b) in col] for col in array
    ]
    array = np.array([[[avg, avg, avg] for avg in col] for col in averages])
    return pygame.surfarray.make_surface(array)
def make_transparent(surface: pygame.Surface, opacity: float = 1) -> pygame.Surface:
    alpha = int(opacity * 255)
    new_surface = surface.copy()
    new_surface.fill((255, 255, 255, alpha), None, pygame.BLEND_RGBA_MULT)
    return new_surface
class PygameDisplay(Display):
    def __init__(self, tetromino_names: dict[int, str]) -> None:
        pygame.init()
        self.title = "Tetris"
        start_grid_size = pygame.Vector2(25, 25)
        self.screen_width = 40
        self.screen_height = self.screen_width // 1.618
        self.screen = pygame.display.set_mode(
            (self.screen_width * start_grid_size.x, self.screen_height * start_grid_size.y),
            pygame.RESIZABLE,
        )
        pygame.display.set_caption(self.title)
        assets = pathlib.Path(__file__).parent / "tetris_ui" / "assets"
        pause_button = ToggleButton(
            pygame.image.load(assets / "play.png"),
            pygame.image.load(assets / "pause.png"),
        )
        pause_button.add_enabled_action(lambda: print("Pause"))
        pause_button.add_disabled_action(lambda: print("Play"))
        mute_button = ToggleButton(
            pygame.image.load(assets / "mute_sound.png"),
            pygame.image.load(assets / "play_sound.png"),
        )
        mute_button.add_enabled_action(lambda: print("Mute"))
        mute_button.add_disabled_action(lambda: print("Play"))
        self.tetris = TetrisRenderer()
        self.tetromino_tiles = TetrominoTiles(
            {
                key: pygame.image.load(assets / "normal-tetromino" / value)
                for key, value in tetromino_names.items()
            },
            pygame.image.load(assets / "normal-tetromino" / "default.png"),
            null_tile_value=0,
        )
        self.tetromino_ghost_tiles = TetrominoTiles(
            {
                key: pygame.image.load(assets / "ghost-tetromino" / value)
                for key, value in tetromino_names.items()                
            },
            pygame.image.load(assets / "ghost-tetromino" / "default.png"),
            null_tile_value=0,
        )
        self.buttons = [pause_button, mute_button]
        self.tetris.set_colors(
            color=(255, 255, 255),
            secondary_color=(50, 50, 50),
            background_color=(0, 0, 0),
        )
        # tetris.set_colors(
        #     color = "cyan",
        #     secondary_color = "purple",
        #     background_color = "dark blue",
        # )
        self.tetris.set_control_buttons(self.buttons)
        self.tetris.set_title(self.title, font="Monospace", scale=2)
        self.tetris.set_text_settings("Berlin Sans FB", scale=1)
        self.tetris.set_outline(3)
    def update(self, state: State) -> None:
        self.tetris.set_board_shape(state.board.T.shape, (1, 1))
        self.tetris.set_boards([
            (state.board, self.tetromino_tiles),
            (state.ghost_tetromino_board, self.tetromino_ghost_tiles),
            (state.current_tetromino_board, self.tetromino_tiles.apply(lambda tile: make_transparent(tile, state.current_tetromino_percent_placed)))
        ])
        self.tetris.set_held_tetromino(
            state.held_tetromino,
            (
                self.tetromino_tiles.apply(gray_scale)
                if state.can_use_held_tetromino
                else self.tetromino_tiles
            ),
        )
        self.tetris.set_queued_tetromino(state.tetromino_queue, self.tetromino_tiles)
        self.tetris.set_info(state.info)
        self.tetris.draw(GridContext.create_from_smallest_rows_and_cols(self.screen, (self.screen_width, self.screen_height)))
        mouse_position = pygame.mouse.get_pos()
        mouse_down = pygame.mouse.get_pressed()[0]
        for button in self.buttons:
            button.update(mouse_position, mouse_down)
            
        pygame.display.flip()from .display import Display
from .pygame_display import PygameDisplay
from .console_display import ConsoleDisplay
__all__ = [
    Display,
    PygameDisplay,
    ConsoleDisplay
import typing
import pygame
from._common import Coordinate
Runnable = typing.Callable[[], None]
def _run(actions: list[Runnable]) -> None:
    for action in actions:
        action()
class ToggleButton:    
    def __init__(self, enable_image: pygame.Surface, disable_image: pygame.Surface) -> None:
        self.position: pygame.Vector2 = None
        self.radius: int = None
                        
        self.enable_image = enable_image
        self.disable_image = disable_image
        
        self.was_mouse_down = self.enabled = self.is_pressed = self.is_hovered = False
        self.on_hovered_actions: list[Runnable] = []
        self.on_pressed_actions: list[Runnable] = []
        self.on_toggled_action: list[Runnable] = []
        self.on_enabled_actions: list[Runnable] = []
        self.on_disabled_actions: list[Runnable] = []
            
    def add_hovered_action(self, func: Runnable) -> None:
        self.on_hovered_actions.append(func)
    def add_pressed_action(self, func: Runnable) -> None:
        self.on_pressed_actions.append(func)
    def add_toggled_action(self, func: Runnable) -> None:
        self.on_toggled_action.append(func)
    def add_enabled_action(self, func: Runnable) -> None:
        self.on_enabled_actions.append(func)
    def add_disabled_action(self, func: Runnable) -> None:
        self.on_disabled_actions.append(func)
    def is_over(self, position: Coordinate) -> bool:
        if self.position is None:
            return False
        return pygame.Vector2(position).distance_to(self.position) <= self.radius
    def update(self, mouse_position: Coordinate, mouse_down: bool = False) -> None:
        
        was_hovered = self.is_hovered
        self.is_hovered = self.is_over(mouse_position)
        if not was_hovered and self.is_hovered:
            _run(self.on_hovered_actions)
        self.is_pressed = self.is_hovered and mouse_down
         
        if self.is_pressed and not self.was_mouse_down:
            self.toggle_state()
            _run(self.on_pressed_actions)
        
        self.was_mouse_down = mouse_down
        
    def get_image(self) -> pygame.Surface:
        image = self.enable_image if self.enabled else self.disable_image
        image = pygame.transform.scale(image, self.size)
        image = pygame.transform.scale_by(image, 1 + (-0.2 if self.is_pressed else 0) + (0.1 if self.is_hovered else 0))
        return image
    
    def put_at_position(self, surface: pygame.Surface, position: Coordinate, circumference: int):
        self.position = pygame.Vector2(position)
        self.radius = circumference / 2
        self.size = pygame.Vector2(circumference, circumference)
        surface.blit(self.get_image(), self.position - (pygame.Vector2(self.get_image().get_size()) / 2))
        
    def enable(self) -> None:
        self.enabled = True
        _run(self.on_enabled_actions)
    def disable(self) -> None:
        self.enabled = False
        _run(self.on_disabled_actions)
    def toggle_state(self) -> None:
        self.enabled = not self.enabled
        _run(self.on_toggled_action + (self.on_enabled_actions if self.enabled else self.on_disabled_actions))
        
    def is_enabled(self) -> bool:
        return self.enabledimport pygame
from pygame import Vector2
from ._common import Coordinate, Size, ColorValue
class Align:
    START = 0
    END = 1
    CENTER = 0.5
class GridContext:
    def __init__(
        self,
        surface: pygame.Surface,
        grid_size: Size,
        *,
        position: Vector2 = None,
        size: Vector2 = None
    ) -> None:
        
        self.surface = surface
        self.grid_pixel_size = pygame.Vector2(grid_size)
        if position is None:
            position = Vector2(0, 0)
        if size is None:
            size = Vector2(
                self.surface.get_width() // self.grid_pixel_size.x,
                self.surface.get_height() // self.grid_pixel_size.y,
            )
        
        self.position = position
        self.size = size
        
    # --- Factory Methods ---
    @classmethod
    def create_from_rows(cls, surface: pygame.Surface, num_of_rows: int):
        size = round(surface.get_height() / num_of_rows)
        return cls(surface, (size, size))
    @classmethod
    def create_from_cols(cls, surface: pygame.Surface, num_of_cols: int):
        size = round(surface.get_width() / num_of_cols)
        return cls(surface, (size, size))
    @classmethod
    def create_from_smallest_rows_and_cols(cls, surface: pygame.Surface, shape: Size):
        num_of_cols, num_of_rows = shape
        size = round(min(surface.get_width() / num_of_cols, surface.get_height() / num_of_rows))
        return cls(surface, (size, size))
    @classmethod
    def create_from_rows_and_cols(cls, surface: pygame.Surface, shape: Size):
        num_of_cols, num_of_rows = shape
        return cls(surface, (round(surface.get_width() / num_of_cols), round(surface.get_height() / num_of_rows)))
    # --- Size Conversion ---
    def to_pixel_relative(self, size: Size) -> Vector2:
        """Convert grid coordinate to pixel location on surface"""
        if isinstance(size, (Vector2)): 
            return size * self.grid_pixel_size.elementwise()
        return self.to_pixel_relative(Vector2(size))
    def to_grid_relative(self, size: Size) -> Vector2:
        """Convert pixel locations on surface to grid coordinate"""
        if isinstance(size, (Vector2)):
            return size / self.grid_pixel_size.elementwise()
        return self.to_grid_relative(Vector2(size))
    # --- Position Conversion ---
    def to_pixel_relative_position(self, position: Coordinate) -> Vector2:
        """Convert grid coordinate to pixel location on surface"""
        if isinstance(position, (Vector2)):
            return (position + self.position) * self.grid_pixel_size.elementwise()
        return self.to_pixel_relative_position(Vector2(position))
    def to_grid_relative_position(self, position: Coordinate) -> Vector2:
        """Convert pixel locations on surface to grid coordinate"""
        if isinstance(position, (Vector2)):
            return position / self.grid_pixel_size.elementwise() - self.position
        return self.to_grid_relative_position(Vector2(position))
    def with_focused_window(
        self,
        position: Coordinate,
        size: Size,
        *,
        alignX=Align.START,
        alignY=Align.START,
    ):  
        position = Vector2(position)
        if position.x < 0:
            position.x = self.get_size().x + position.x
        if position.y < 0:
            position.y = self.get_size().y + position.y
        if size is None:
            size = self.get_size() - position
            
        size = Vector2(size)
        if size.x < 0:
            size.x = self.get_size().x + size.x
        if size.y < 0:
            size.y = self.get_size().y + size.y
        position.x += self.position.x
        position.y += self.position.y
        position.x -= size.x * alignX
        position.y -= size.y * alignY
        return self.__class__(self.surface, self.grid_pixel_size, position = position, size = size)
    # --- Pixel Surface Getters ---
    def get_pixels_cell_size(self) -> Vector2:
        """Get pixel size of individual grid cell"""
        return self.grid_pixel_size
    # --- Grid Getters ---
    def get_size(self) -> Vector2:
        """Get width and height of focused grid"""
        return Vector2(self.size)
    # --- Context Operations ---
    def fill(self, color: ColorValue) -> None:
        """Fill focused area with color"""
        pygame.draw.rect(
            self.surface,
            color,
            pygame.Rect(
                self.to_pixel_relative(self.position),
                self.to_pixel_relative(self.size),
            ),
        )
    def outline(self, pixels_thickness: int, color: ColorValue) -> None:
        
        offset = 0 if pixels_thickness < 0 else pixels_thickness
        pygame.draw.rect(
            self.surface,
            color,
            pygame.Rect(
                self.to_pixel_relative(self.position) - (offset, offset),
                self.to_pixel_relative(self.size) + (offset * 2, offset * 2),
            ),
            width=abs(pixels_thickness),
        )
    def blit(
        self,
        source: pygame.Surface,
        destination: Coordinate,
        *,
        alignX=Align.START,
        alignY=Align.START,
    ) -> None:
        """Blit source onto focused area"""
        x, y = self.to_pixel_relative_position(destination)
        x -= source.get_width() * alignX
        y -= source.get_height() * alignY
        self.surface.blit(source, (x, y))
import pygame
from .grid import GridContext, Align
from .tetromino import TetrominoTiles
from .button import ToggleButton
from ._common import ColorValue, Size
Grid = list[list[int]]
def _get_grid_size(grid: Grid) -> pygame.Vector2:
    height = len(grid)
    width = height and len(grid[0])
    return pygame.Vector2(width, height)
# View Render
class TetrisRenderer:
    def __init__(self) -> None:
        self.set_board_shape()
        self.set_boards()
        self.set_colors()
        self.set_control_buttons()
        self.set_held_tetromino()
        self.set_info()
        self.set_outline()
        self.set_queued_tetromino()
        self.set_text_settings()
        self.set_title()
    # --- Stateless drawing methods ----
    def _draw_items_box(
        self, grid: GridContext, padding=1, title: str = None
    ) -> GridContext:
        grid.fill(self.secondary_color)
        grid.outline(self.outline_thickness_pixels, self.outline_color)
        offset = pygame.Vector2(padding, padding)
        inner_grid = grid.with_focused_window(offset, grid.get_size() - offset * 2)
        if title is not None:
            self._draw_item_title(
                inner_grid.with_focused_window(
                    (0, 0), (inner_grid.get_size().x, self.text_scale)
                ),
                title,
            )
            inner_grid = inner_grid.with_focused_window((0, self.text_scale), None)
        return inner_grid
    def _draw_board(self, grid: GridContext, shape: Size, cell_size: Size):
        grid.outline(self.outline_thickness_pixels, self.outline_color)
        grid_cell = pygame.Surface(grid.to_pixel_relative(cell_size), pygame.SRCALPHA)
        pygame.draw.rect(
            grid_cell,
            self.secondary_color,
            pygame.Rect((0, 0), grid_cell.get_size()),
            width=1,
        )
        for x in range(int(shape.x)):
            for y in range(int(shape.y)):
                grid.blit(grid_cell, (x, y))
    def _draw_tetromino_grid(
        self,
        grid: GridContext,
        tetromino: Grid,
        tetromino_tiles: TetrominoTiles,
        size: Size = (1, 1),
    ) -> None:
        squares = tetromino_tiles.get_tetromino_tiles(
            tetromino, size=grid.to_pixel_relative(size)
        )
        for y, row in enumerate(squares):
            for x, square in enumerate(row):
                if square:
                    grid.blit(
                        square,
                        (x, y),
                    )
    def _draw_item_text(
        self,
        grid: GridContext,
        text: str,
        color: ColorValue,
        background: ColorValue = None,
        font_font="Berlin Sans FB",
    ) -> None:
        if background:
            grid.fill(background)
        font = pygame.font.SysFont(
            font_font,
            round(grid.get_size().y * grid.get_pixels_cell_size().y),
            False,
            False,
        )
        text_surface = font.render(text, True, color)
        grid.blit(
            text_surface,
            grid.get_size() / 2,
            alignX=Align.CENTER,
            alignY=Align.CENTER,
        )
    def _draw_item_title(self, grid: GridContext, title: str) -> None:
        self._draw_item_text(
            grid,
            title.upper(),
            self.color,
            None,
        )
    def _create_title(
        self, title: str, font_size: int, font_name="Monospace"
    ) -> pygame.Surface:
        title_font = pygame.font.SysFont(font_name, int(font_size), True, False)
        title_surface = title_font.render(title, True, self.color)
        return title_surface
    def _draw_info(
        self,
        grid: GridContext,
        info: dict[str, str],
        text_size: int,
        vertical_gap: int = 0,
    ) -> None:
        height = 0
        box_size = pygame.Vector2(grid.get_size().x, text_size)
        for title, data in info.items():
            self._draw_item_title(
                grid.with_focused_window((0, height), box_size), title
            )
            height += box_size.y
            self._draw_item_text(
                grid.with_focused_window((0, height), box_size),
                data,
                self.color,
                self.background_color,
            )
            height += box_size.y
            height += vertical_gap
    def _draw_buttons(
        self, grid: GridContext, buttons: list[ToggleButton]
    ) -> ToggleButton:
        if len(buttons) == 0:
            return
        x_split = grid.get_size().x / len(buttons)
        y = grid.get_size().y / 2
        for i, button in enumerate(buttons):
            button.put_at_position(
                grid.surface,
                grid.to_pixel_relative_position((x_split * i + x_split / 2, y)),
                grid.get_pixels_cell_size().y * 2,
            )
    def _draw_tetrominoes(
        self,
        grid: GridContext,
        tetrominoes: list[Grid],
        tetromino_tiles: TetrominoTiles,
    ) -> None:
        if len(tetrominoes) == 0:
            return
        x = grid.get_size().x / 2
        y_split = grid.get_size().y / len(tetrominoes)
        for i, tetromino in enumerate(tetrominoes):
            size = _get_grid_size(tetromino)
            self._draw_tetromino_grid(
                grid.with_focused_window(
                    (x, y_split * i + y_split / 2),
                    size,
                    alignX=Align.CENTER,
                    alignY=Align.CENTER,
                ),
                tetromino,
                tetromino_tiles,
            )
    def set_colors(
        self,
        color: ColorValue = (255, 255, 255),
        background_color: ColorValue = (0, 0, 0),
        secondary_color: ColorValue = (50, 50, 50),
    ):
        self.color = color
        self.secondary_color = secondary_color
        self.background_color = background_color
    def set_title(self, title: str = None, font: str = "Monospace", scale: float = 1):
        self.title = self.__class__.__name__.title() if title is None else title
        self.title_font = font
        self.title_scale = scale
        return self
    def set_outline(self, pixel_width: int = 1, color: ColorValue = None):
        self.outline_thickness_pixels = pixel_width
        self.outline_color = color or self.color
    def set_text_settings(self, font: str = "Monospace", scale: float = 1):
        self.font = font
        self.text_scale = scale
        return self
    def set_board_shape(self, shape: Size = (10, 20), cell_size=(1, 1)):
        self.board_shape = pygame.Vector2(shape)
        self.board_cell_size = pygame.Vector2(cell_size)
        return self
    def set_boards(self, boards: list[tuple[Grid, TetrominoTiles]] = []):
        self.boards = boards
        for board, tetromino_tiles in self.boards:
            assert _get_grid_size(board) == self.board_shape, ValueError(
                f"Board shape must be set board shape of {self.board_shape}"
            )
        return self
    def set_queued_tetromino(
        self, queue: list[Grid] = [], tetromino_tiles: TetrominoTiles = None
    ):
        self.queued_tetromino = queue
        self.queued_tetromino_tiles = tetromino_tiles
        return self
    def set_held_tetromino(
        self, held: Grid = None, tetromino_tiles: TetrominoTiles = None
    ):
        self.held_tetromino = held
        self.held_tetromino_tiles = tetromino_tiles
        return self
    def set_info(self, info: dict[str, str] = {}):
        self.info = info
        return self
    def set_control_buttons(self, buttons: list[ToggleButton] = []) -> None:
        self.buttons = buttons
        return self
    def draw(
        self,
        grid: GridContext,
    ) -> None:
        # --- Full ---
        grid.fill(self.background_color)
        # --- Center ---
        title_surface = self._create_title(
            self.title,
            self.title_scale * grid.get_pixels_cell_size().y,
            self.title_font,
        )
        title_height = title_surface.get_height() / grid.get_pixels_cell_size().y
        # Board
        board_size = self.board_shape.elementwise() * self.board_cell_size
        board_location = (grid.get_size() - board_size) / 2 + (0, title_height / 4)
        board_grid = grid.with_focused_window(board_location, board_size)
        self._draw_board(board_grid, self.board_shape, self.board_cell_size)
        for board, tetromino_tiles in self.boards:
            self._draw_tetromino_grid(board_grid, board, tetromino_tiles)
        # Title
        inner_title_grid = grid.with_focused_window(
            board_location,
            (board_size.x, title_height),
            alignY=Align.END,
        )
        inner_title_grid.blit(
            title_surface,
            inner_title_grid.get_size() / 2,
            alignX=Align.CENTER,
            alignY=Align.CENTER,
        )
        # ----- Side Panels -----
        SIDE_BOARD_WIDTH = 7
        UPPER_SIDE_BOARD_HEIGHT = 13
        LOWER_SIDE_BOARD_HEIGHT = 7
        SIDE_BOARD_PADDING = 1
        # --- Left ---
        # Info
        inner_info_grid = self._draw_items_box(
            grid.with_focused_window(
                board_location - (1, 0),
                (SIDE_BOARD_WIDTH, UPPER_SIDE_BOARD_HEIGHT),
                alignX=Align.END,
            ),
            padding=SIDE_BOARD_PADDING,
        )
        self._draw_info(
            inner_info_grid,
            self.info,
            text_size=self.text_scale,
            vertical_gap=SIDE_BOARD_PADDING,
        )
        # Buttons
        inner_control_grid = self._draw_items_box(
            grid.with_focused_window(
                board_location + (0, board_size.y) - (1, 0),
                (SIDE_BOARD_WIDTH, LOWER_SIDE_BOARD_HEIGHT),
                alignX=Align.END,
                alignY=Align.END,
            ),
            padding=SIDE_BOARD_PADDING,
            title="controls",
        )
        inner_control_grid.fill(self.background_color)
        self._draw_buttons(inner_control_grid, self.buttons)
        # --- Right ---
        # Queue
        inner_queue_grid = self._draw_items_box(
            grid.with_focused_window(
                board_location + (board_size.x, 0) + (1, 0),
                (SIDE_BOARD_WIDTH, UPPER_SIDE_BOARD_HEIGHT),
                alignX=Align.START,
            ),
            padding=SIDE_BOARD_PADDING,
            title="queue",
        )
        inner_queue_grid.fill(self.background_color)
        self._draw_tetrominoes(
            inner_queue_grid, self.queued_tetromino, self.queued_tetromino_tiles
        )
        # Held
        inner_held_grid = self._draw_items_box(
            grid.with_focused_window(
                board_location + board_size + (1, 0),
                (SIDE_BOARD_WIDTH, LOWER_SIDE_BOARD_HEIGHT),
                alignY=Align.END,
            ),
            padding=SIDE_BOARD_PADDING,
            title="held",
        )
        inner_held_grid.fill(self.background_color)
        self._draw_tetrominoes(
            inner_held_grid,
            [] if self.held_tetromino is None else [self.held_tetromino],
            self.held_tetromino_tiles,
        )
from typing import Self, Callable
import pygame
from ._common import ColorValue, Size, FileArg
def _load_image(filename: str, fallback_image: pygame.Surface) -> pygame.Surface:
    try:
        return pygame.image.load(filename)
    except FileNotFoundError:
        return fallback_image
    
def _create_square(color: ColorValue = None) -> pygame.Surface:
    surface = pygame.Surface((1, 1))
    if color is not None: surface.fill(color)
    return surface
class TetrominoTiles:
    def __init__(
        self,
        tetromino_tiles: dict[int, pygame.Surface],
        missing_tetrominoes_tile: pygame.Surface = None,
        null_tile_value: int = 0
    ) -> None:
        self.tetrominoes_tiles = tetromino_tiles
        if missing_tetrominoes_tile is None:
            missing_tetrominoes_tile = _create_square()
        self.missing_tetromino_tile = missing_tetrominoes_tile
        self.null_tile_value = null_tile_value
    @classmethod
    def from_image_files(
        cls,
        tetromino_tile_filenames: dict[str, FileArg],
        missing_tetromino_filename: FileArg = None,
        null_tile_value: int = 0,
    ):
        
        missing_tetrominoes_tile = _load_image(missing_tetromino_filename, _create_square())
        return cls(
            {key: _load_image(image, missing_tetrominoes_tile) for key, image in tetromino_tile_filenames.items()},
            missing_tetrominoes_tile,
            null_tile_value,
        )
    @classmethod
    def from_colors(
        cls,
        tetromino_tile_filenames: dict[str, ColorValue],
        missing_tetromino_color: ColorValue = None,
        null_tile_value: int = 0,
    ):
        return cls(
            {key: _create_square(color) for key, color in tetromino_tile_filenames.items()},
            _create_square(missing_tetromino_color),
            null_tile_value,
        )
    
    def apply(self, func: Callable[[pygame.Surface], pygame.Surface]):
        return self.__class__(
            tetromino_tiles = {key: func(tile) for key, tile in self.tetrominoes_tiles.items()},
            missing_tetrominoes_tile = func(self.missing_tetromino_tile),
            null_tile_value = self.null_tile_value
        )
    def get_tetromino_tile(self, tetromino_key: int, *, size: Size = None) -> pygame.Surface | None:
        if tetromino_key == self.null_tile_value:
            return None
        tile = self.tetrominoes_tiles.get(tetromino_key, self.missing_tetromino_tile)
        if size is not None:
            tile = pygame.transform.scale(tile, size)
        
        return tile
    def get_tetromino_tiles(
        self, tetromino_key_grid: list[list[int]], size: Size = None
    ) -> list[list[pygame.Surface | None]]:
        return [
            [self.get_tetromino_tile(tetromino_key, size=size) for tetromino_key in row]
            for row in tetromino_key_grid
        ]
from os import PathLike
from typing import IO, Sequence, Tuple, Union
from pygame.color import Color
from pygame.math import Vector2
AnyPath = Union[str, bytes, PathLike[str], PathLike[bytes]]
FileArg = Union[AnyPath, IO[bytes], IO[str]]
Coordinate = Union[Tuple[float, float], Sequence[float], Vector2]
Size = Union[Tuple[float, float], Sequence[float], Vector2]
RGBAOutput = Tuple[int, int, int, int]
ColorValue = Union[Color, int, str, Tuple[int, int, int], RGBAOutput, Sequence[int]]from .grid import GridContext
from .tetromino import TetrominoTiles
from .button import ToggleButton
from .tetris import TetrisRenderer
assets = __import__("pathlib").Path(__file__).parent / "tetris_ui" / "assets"
__all__ = [
    GridContext,
    TetrominoTiles,
    ToggleButton,
    TetrisRenderer
import numpy as np
from game_actions import Action
from game_state import State
from .model import Model
from .tetris import (
    TetrisGameManager,
    Grid,
    ShuffledBagQueue,
    TetrominoShape,
    LevelManager,
    ScoreManger,
    TimeManager,
    Event,
class BasicModel(Model):
    def __init__(self) -> None:
        NULL_VALUE = 0
        board = Grid.empty(shape=(10, 20), null_value=NULL_VALUE)
        tetromino_shapes = [
            TetrominoShape(
                "I",
                [
                    [0, 0, 0, 0],
                    [1, 1, 1, 1],
                    [0, 0, 0, 0],
                    [0, 0, 0, 0],
                ],
                null_value=NULL_VALUE
            ),
            TetrominoShape(
                "O",
                [
                    [1, 1],
                    [1, 1],
                ],
                null_value=NULL_VALUE
            ),
            TetrominoShape(
                "L",
                [
                    [0, 0, 1],
                    [1, 1, 1],
                    [0, 0, 0],
                ],
                null_value=NULL_VALUE
            ),
            TetrominoShape(
                "J",
                [
                    [1, 0, 0],
                    [1, 1, 1],
                    [0, 0, 0],
                ],
                null_value=NULL_VALUE
            ),
            TetrominoShape(
                "T",
                [
                    [0, 1, 0],
                    [1, 1, 1],
                    [0, 0, 0],
                ],
                null_value=NULL_VALUE
            ),
            TetrominoShape(
                "Z",
                [
                    [1, 1, 0],
                    [0, 1, 1],
                    [0, 0, 0],
                ],
                null_value=NULL_VALUE
            ),
            TetrominoShape(
                "S",
                [
                    [0, 1, 1],
                    [1, 1, 0],
                    [0, 0, 0],
                ],
                null_value=NULL_VALUE
            ),
        ]
        piece_queue = ShuffledBagQueue(tetromino_shapes, visible_size=3)
        level_manager = LevelManager(
            lines_for_next_level=10,
        )
        score_manager = ScoreManger(
            for_line_clear=[0, 40, 100, 300, 1200],
            for_events={Event.SOFT_DROP: 1, Event.HARD_DROP: 2}
        )
        time_manager = TimeManager(
            fps=60
        )
        self.game_manager = TetrisGameManager(board, piece_queue)
    def reset(self) -> None:
        self.game_manager.reset()
    def update(self, actions: list[Action]) -> State:
        self.game_manager.step(actions)
        return State(
            self.game_manager.get_board(),
            self.game_manager.get_current_piece_board(),
            self.game_manager.get_piece_percent_placed(),
            self.game_manager.get_ghost_board(),
            self.game_manager.get_held_tetromino(),
            self.game_manager.can_use_held_tetromino(),
            self.game_manager.get_tetromino_queue(),
            {},
            False,
            self.game_manager.get_array_null_value())
from game_actions import Action
from game_state import State
class Model:
    def reset(self) -> None:
        pass
    
    def update(actions: list[Action]) -> State:
        return State(None, None, 0, None, None, False, {})from .model import Model
from .basic_model import BasicModel
__all__ = [
    Model,
    BasicModel
import enum as _enum
class Event(_enum.Enum):
    SPIN = _enum.auto()
    LEFT = _enum.auto()
    RIGHT = _enum.auto()
    SOFT_DROP = _enum.auto()
    HARD_DROP = _enum.auto()
    HOLD = _enum.auto()
    # Could add T-SPIN, Perfect Clear, etc
    
import numpy as np
from game_actions import Action
from .grid import Grid
from .refill_queue import RefillingQueue
from .tetromino import TetrominoShape, Tetromino
# Model
class TetrisGameManager:
    def __init__(
        self, board: Grid, tetromino_shape_queue: RefillingQueue[TetrominoShape]
    ) -> None:
        self.board = board
        self.tetromino_shape_queue = tetromino_shape_queue
        self.falling_tetromino: Tetromino = None
        self.held_tetromino: Tetromino = None
    def reset(self):
        self.board.clear()
        self.tetromino_shape_queue.reset()
        self.falling_tetromino = None
        self.frame = 0
    def get_board(self) -> np.ndarray:
        return self.board.get_grid_array()
    def get_current_piece_board(self) -> np.ndarray:
        grid = Grid.empty_like(self.board)
        if self.falling_tetromino is not None:
            grid.insert(self.falling_tetromino.get_position(),
                        self.falling_tetromino.get_grid_array())
        return grid.get_grid_array()
    def get_piece_percent_placed(self) -> float:
        return 0
    def get_ghost_board(self) -> np.ndarray:
        empty_board = Grid.empty_like(self.board)
        if self.falling_tetromino is None:
            return empty_board.get_grid_array()
        
        ghost = self.falling_tetromino.copy()
        while not self.board.does_overlap(ghost.get_position(), ghost.get_grid_array()):
            ghost.move(dy=1)
        ghost.move(dy=-1)
        empty_board.insert(
            self.falling_tetromino.get_position(),
            self.falling_tetromino.get_grid_array(),
        )
        return empty_board.get_grid_array()
    def get_held_tetromino(self) -> np.ndarray | None:
        if self.held_tetromino is None:
            return None
        return self.held_tetromino.get_grid_array()
    def can_use_held_tetromino(self) -> bool:
        return False
    def get_tetromino_queue(self) -> list[np.ndarray]:
        return [shape.get_grid_array() for shape in self.tetromino_shape_queue.view()]
    def get_array_null_value(self) -> int:
        return self.board.get_null_value()
    def _get_next_falling_tetromino(self) -> Tetromino:
        tetromino_shape = self.tetromino_shape_queue.pop()
        tetromino_start_orientation = 0
        tetromino_start_x = (
            self.board.get_width()
            - tetromino_shape.get_width(tetromino_start_orientation)
        ) // 2
        tetromino_start_y = 0
        return Tetromino(
            tetromino_shape, (tetromino_start_x,
                              tetromino_start_y), tetromino_start_orientation
        )
    def change_x(self, dx: int) -> bool:
                
        self.falling_tetromino.move(dx, 0)
        
        if self.board.does_overlap(self.falling_tetromino.get_position(), self.falling_tetromino.get_grid_array()):
            self.falling_tetromino.move(-dx, 0)
            return False
        
        return True
    def rotate(self, rotations: int) -> bool:
        positions_to_try = [(0, 0)]
        if True:
            positions_to_try.extend([(1, 0), (-1, 0)])
        for (dx, dy) in positions_to_try:
            self.falling_tetromino.move(dx, dy)
            old_orientation = self.falling_tetromino.orientation
            self.falling_tetromino.rotate(rotations)
            if self.board.does_overlap(self.falling_tetromino.get_position(), self.falling_tetromino.get_grid_array()):
                self.falling_tetromino.orientation = old_orientation
            else:
                return True
            self.falling_tetromino.move(-dx, -dy)
        
        return False
    def step(self, actions: list[Action]):
        if self.falling_tetromino is None:
            self.falling_tetromino = self._get_next_falling_tetromino()
        self.falling_tetromino.move(dy=1)
        did_collide = self.board.does_overlap(
            self.falling_tetromino.get_position(),
            self.falling_tetromino.get_grid_array(),
        )
        for action in actions:
            match action:
                case Action.LEFT: self.change_x(-1)
                case Action.RIGHT: self.change_x(1)
                case Action.SPIN: self.rotate(1)
                
        if did_collide:
            self.falling_tetromino.move(dy=-1)
            did_collide = self.board.insert(
                self.falling_tetromino.get_position(),
                self.falling_tetromino.get_grid_array(),
            )
            self.falling_tetromino = None
from .game_manager import TetrisGameManager
from .grid import Grid
from .refill_queue import (
    RefillingQueue,
    FullRandomQueue,
    LessRepeatRandomQueue,
    ShuffledBagQueue,
from .scores.scores_manager import HighScoreManager, JSONFileHighScoreStorage
from .tetromino import TetrominoShape, Tetromino
from .side_board import LevelManager, ScoreManger, TimeManager
from .game_events import Event
__all__ = [
    TetrisGameManager,
    Event,
    Grid,
    RefillingQueue,
    FullRandomQueue,
    LessRepeatRandomQueue,
    ShuffledBagQueue,
    HighScoreManager,
    JSONFileHighScoreStorage,
    TetrominoShape,
    Tetromino,
    LevelManager,
    ScoreManger,
    TimeManager
from typing import Generator, Self
import numpy as np
CoordinatePair = tuple[int, int]
WidthHeightPair = tuple[int, int]
def find_corners(grid: np.ndarray, null_value=0) -> tuple[CoordinatePair, CoordinatePair]:
    empty_positions = np.where(grid != null_value)
    y_start = min(empty_positions[0])
    y_end = max(empty_positions[0]) + 1
    x_start = min(empty_positions[1])
    x_end = max(empty_positions[1]) + 1
    return ((x_start, y_start), (x_end, y_end))
class Grid:
    def __init__(self, grid: np.ndarray, null_value=0) -> None:
        self.grid = grid
        self.null_value = null_value
        self.clear()
    @classmethod
    def empty(cls, shape: WidthHeightPair, null_value=0, dtype=int) -> Self:
        width, height = shape
        new = cls(np.empty((height, width), dtype=dtype), null_value)
        new.clear()
        return new
    @classmethod
    def empty_like(cls, prototype: Self) -> Self:
        new = cls(np.empty_like(prototype.get_grid_array()), prototype.get_null_value())
        new.clear()
        return new
    def clear(self) -> None:
        self.grid.fill(self.null_value)
    def get_grid_array(self) -> np.ndarray:
        return self.grid
    def get_null_value(self) -> np.ndarray:
        return self.null_value
    def insert(self, position: CoordinatePair, subgrid: np.ndarray) -> None:
        """Put subgrid at specified position in main grid, EMPTY values will not be set"""
        x, y = position
        ((x_start, y_start), (x_end, y_end)) = find_corners(subgrid)
        subgrid = subgrid[y_start:y_end, x_start:x_end]
        x, y = x + x_start, y + y_start
        width, height = x_end - x_start, y_end - y_start
        view = self.grid[y : y + height, x : x + width]
        mask = subgrid != self.null_value
        view[mask] = subgrid[mask]
    def insert_if_empty(self, position: CoordinatePair, subgrid: np.ndarray) -> bool:
        """if subgrid does not overlap, insert it and return true"""
        x, y = position
        ((x_start, y_start), (x_end, y_end)) = find_corners(subgrid)
        subgrid = subgrid[y_start:y_end, x_start:x_end]
        x, y = x + x_start, y + y_start
        width, height = x_end - x_start, y_end - y_start
        view = self.grid[y : y + height, x : x + width]
        if view.shape != subgrid.shape:
            return False
        mask = subgrid != self.null_value
        # Check to see if there is any overlap
        if np.logical_and(view[mask], subgrid[mask]).any():
            return False
        # Set values in grid by setting view
        view[mask] = subgrid[mask]
        return True
    def insert_empty(
        self, position: CoordinatePair, subgrid_mask: np.ndarray[bool]
    ) -> None:
        """Clear all values at specified position where subgrid_mask is True"""
        x, y = position
        height, width = subgrid_mask.shape
        view = self.grid[y : y + height, x : x + width]
        view[subgrid_mask.astype(bool)] = 0
    def does_overlap(self, position: CoordinatePair, subgrid: np.ndarray) -> bool:
        """check if subgrid overlaps with anything in grid at specified position"""
        x, y = position
        ((x_start, y_start), (x_end, y_end)) = find_corners(subgrid)
        subgrid = subgrid[y_start:y_end, x_start:x_end]
        x, y = x + x_start, y + y_start
        width, height = x_end - x_start, y_end - y_start
        view = self.grid[y : y + height, x : x + width]
        if view.shape != subgrid.shape:
            return True
        mask = subgrid != self.null_value
        # Check to see if there is any overlap
        return np.logical_and(view[mask], subgrid[mask]).any()
    def get_grid_string(
        self, row_template_str="[%s]", full_tile_template_str=" %s", empty_tile_str="  "
    ) -> str:
        return "\n".join(
            row_template_str
            % (
                "".join(
                    (
                        full_tile_template_str % item
                        if (item != self.null_value)
                        else empty_tile_str
                    )
                    for item in row
                )
            )
            for row in self.grid
        )
    def get_height(self) -> int:
        return self.grid.shape[0]
    def get_width(self) -> int:
        return self.grid.shape[1]
    def copy(self):
        return self.__class__(self.grid.copy(), self.null_value)
    def __iter__(self) -> Generator[tuple[int, CoordinatePair], None, None]:
        for row in range(self.get_height()):
            for col in range(self.get_width()):
                yield (self.grid[row, col], (row, col))
    def __str__(self) -> str:
        return self.get_grid_string()
from .grid import Grid
__all__ = [Grid]
from abc import ABC, abstractmethod
import random
from typing import TypeVar, Generic, Iterable
_T = TypeVar("_T")
class RefillingQueue(ABC, Generic[_T]):
    def __init__(self, refill_items: Iterable[_T], visible_size: int = 1) -> None:
        self.refill_items = list(refill_items)
        self.visible_size = visible_size
        self.queue = []
        self.reset()
    def get_view_size(self) -> int:
        return self.visible_size
    def insert_at_start(self, items: list[_T]) -> None:
        self.queue = items + self.queue
    def pop(self) -> _T:
        value = self.queue.pop(0)
        self.fill_queue()
        return value
    def view(self) -> list[_T]:
        return self.queue[self.visible_size :]
    def reset(self) -> None:
        self.queue.clear()
        self.fill_queue()
    def fill_queue(self):
        while len(self.queue) < self.visible_size:
            self.queue.append(self.generate())
    @abstractmethod
    def generate() -> _T:
        pass
class FullRandomQueue(RefillingQueue[_T]):
    def generate(self) -> _T:
        return random.choice(self.refill_items)
class ShuffledBagQueue(RefillingQueue[_T]):
    def reset(self) -> None:
        self.refill_items_shuffled = []
        super().reset()
    def generate(self) -> _T:
        if len(self.refill_items_shuffled) < 1:
            self.refill_items_shuffled = self.refill_items.copy()
            random.shuffle(self.refill_items_shuffled)
        return self.refill_items_shuffled.pop()
class ShuffledDoubledBagQueue(RefillingQueue[_T]):
    def reset(self) -> None:
        self.refill_items_shuffled = []
        super().reset()
    def generate(self) -> _T:
        if len(self.refill_items_shuffled) < 1:
            self.refill_items_shuffled = self.refill_items + self.refill_items
            random.shuffle(self.refill_items_shuffled)
        return self.refill_items_shuffled.pop()
class LessRepeatRandomQueue(RefillingQueue[_T]):
    def reset(self) -> None:
        self.last_roll_num = None
        super().reset()
    def generate(self) -> _T:
        roll_num = random.randrange(-1, len(self.refill_items))
        if roll_num in (-1, self.last_roll_num):
            roll_num = random.randrange(0, len(self.refill_items))
        self.last_roll_num = roll_num
        return self.refill_items[roll_num]
import random
from typing import TypeVar, Generic, Callable, Generator, Iterable
_T = TypeVar("_T")
class RefillingQueue(Generic[_T]):
    def __init__(
        self,
        refill_items: Iterable[_T],
        generator_function: Callable[[_T], Generator[_T, None, None]],
        visible_size: int = 1,
    ) -> None:
        self.refill_items = list(refill_items)
        self.generator_function = generator_function
        self.visible_size = visible_size
        self.queue = []
        self.reset()
    def insert_at_start(self, items: Iterable[_T]) -> None:
        self.queue = list(items) + self.queue
    def pop(self) -> _T:
        value = self.queue.pop(0)
        self.fill_queue()
        return value
    def view(self) -> list[_T]:
        return self.queue[self.visible_size :]
    def reset(self) -> None:
        self.queue.clear()
        self.generator = self.generator_function(self.refill_items)
        self.fill_queue()
    def fill_queue(self):
        while len(self.queue) < self.visible_size:
            self.queue.append(next(self.generator))
def full_random_generator(items: list[_T]) -> Generator[_T, None, None]:
    while True:
        yield random.choice(items)
def shuffled_double_bag_generator(items: list[_T]) -> Generator[_T, None, None]:
    items = items.copy()
    while True:
        yield from items
        random.shuffle(items)
def shuffled_double_bag_generator(items: list[_T]) -> Generator[_T, None, None]:
    items = items + items
    while True:
        yield from items
        random.shuffle(items)
def less_repeat_random_generator(items: list[_T]) -> Generator[_T, None, None]:
    last_num = None
    while True:
        roll_num = random.randrange(-1, len(items))
        if roll_num in (-1, last_num):
            roll_num = random.randrange(0, len(items))
        last_num = roll_num
        yield items[roll_num]
from .refilling_queue import (
    RefillingQueue,
    FullRandomQueue,
    LessRepeatRandomQueue,
    ShuffledBagQueue,
__all__ = [RefillingQueue, FullRandomQueue, LessRepeatRandomQueue, ShuffledBagQueue]
from abc import ABC, abstractmethod
from dataclasses import dataclass, asdict
from typing import Optional
import heapq
import json
@dataclass(slots=True, frozen=True)
class Score:
    score: int
    time: float
    playerName: str
class HighScoreManager(ABC):
    @abstractmethod
    def save_score(self, score: Score) -> None:
        pass
    @abstractmethod
    def get_top_scores(self, n: int) -> list[Score]:
        pass
    @abstractmethod
    def get_top_score(self) -> Optional[Score]:
        pass
class JSONFileHighScoreStorage(HighScoreManager):
    def __init__(self, file_path: str):
        self.file_path = file_path
        self._load_scores()
    def save_score(self, score: Score) -> None:
        heapq.heappush(self.scores, score)
        self._load_scores()
    def get_top_scores(self, n: int) -> list[Score]:
        if len(self.scores) < 1:
            return None
        return heapq.nlargest(n, self.scores)
    def _load_scores(self) -> list[Score]:
        try:
            with open(self.file_path, "r") as file:
                scores_data = json.load(file)
        except (FileNotFoundError, json.JSONDecodeError):
            scores_data = []
        self.scores = heapq.heapify([Score(**score) for score in scores_data])
    def _save_scores(self) -> None:
        with open(self.file_path, "w") as file:
            json.dump([asdict(score) for score in self.scores], file, indent=4)
from .scores_manager import Score, HighScoreManager, JSONFileHighScoreStorage
__all__ = [Score, HighScoreManager, JSONFileHighScoreStorage]
from ..game_events import Event
from . import Manager
class LevelManager(Manager):
    def __init__(self, lines_for_next_level: int) -> None:
        self.lines_for_next_level = lines_for_next_level
        self.reset()
    def reset(self) -> None:
        self.level = 0
    
    def handle_event(self, event: dict[Event, object]) -> None:
        return super().handle_event(event)
    def get_level(self) -> int:
        return self.levelfrom abc import ABC, abstractmethod
from ..game_events import Event
class Manager(ABC):
    
    @abstractmethod
    def handle_event(self, event: dict[Event, object]) -> None:
        pass
    @abstractmethod
    def reset(self) -> None:
        passfrom ..game_events import Event
from . import Manager
class ScoreManger(Manager):
    
    def __init__(self, for_line_clear: list[int], for_events: dict[Event, int]) -> None:
        self.for_line_clear = for_line_clear
        self.for_action = for_events
        self.reset()
    
    def handle_event(self, event: dict[Event, object]) -> None:
        return super().handle_event(event)
    def reset(self) -> None:
        self.score = 0from ..game_events import Event
from . import Manager
class TimeManager(Manager):
    def __init__(self, fps: int) -> None:
        self.fps = fps
    
    def reset(self) -> None:
        self.frame = 0
    
    def handle_event(self, event: dict[Event, object]) -> None:
        return super().handle_event(event)
    
    def tick(self):
        self.frame += 1
    def get_time_str(self) -> str:
        if self.fps == 0: return "Inf"
        seconds = self.frame / self.fps
        minutes, seconds = divmod(seconds, 60)
        return f"{minutes:.0f}:{seconds:0>2.0f}"
    def get_fps(self) -> int:
        return self.fpsfrom .manager import Manager
from .level_manager import LevelManager
from .score_manager import ScoreManger
from .time_manager import TimeManager
__all__ = [LevelManager, ScoreManger, TimeManager]import numpy as np
def rotate(grid: np.ndarray) -> np.ndarray:
    return np.flip(np.rot90(grid))
class TetrominoShape:
    MAX_ORIENTATIONS = 4
    def __init__(self, name: str, shape: np.ndarray, null_value = 0) -> None:
        self.name = name
        self.bytes = np.array(shape).tobytes()
        self.null_value = null_value
        shape_array = np.where(shape, hash(self), self.null_value).astype(int)
        self.orientations: list[np.ndarray] = []
        for i in range(TetrominoShape.MAX_ORIENTATIONS):
            self.orientations.append(shape_array)
            shape_array = rotate(shape_array)
            if np.array_equal(shape_array, self.orientations[0]):
                break
    def get_name(self) -> str:
        return self.name
    def get_grid_array(self, orientation=0) -> np.ndarray:
        return self.orientations[orientation]
    def get_width(self, orientation=0) -> int:
        return self.get_grid_array(orientation).shape[1]
    def get_height(self, orientation=0) -> int:
        return self.get_grid_array(orientation).shape[0]
    def get_thumbnail_grid_array(self) -> np.ndarray:
        grid = self.get_grid_array(0)
        empty_positions = np.where(grid != self.null_value)
        trimmed_grid = grid[
            min(empty_positions[0]) : max(empty_positions[0]) + 1,
            min(empty_positions[1]) : max(empty_positions[1]) + 1,
        ]
        return trimmed_grid
    def __str__(self) -> str:
        return f"{self.__class__.__name__}({self.get_name()}, {self.get_grid_array()})"
    def __hash__(self) -> int:
        return hash((self.get_name(), self.bytes))from typing import Generator, Self
import numpy as np
from .shape import TetrominoShape
CoordinatePair = tuple[int, int]
class Tetromino:
    def __init__(
        self,
        shape: TetrominoShape,
        start_position: CoordinatePair = (0, 0),
        orientation: int = 0,
    ) -> None:
        self.shape = shape
        self.goto(start_position)
        self.set_orientation(orientation)
    def get_name(self) -> str:
        return self.shape.get_name()
    def get_height(self) -> int:
        return self.get_grid_array().shape[1]
    def get_width(self) -> int:
        return self.get_grid_array().shape[0]
    def get_grid_array(self) -> np.ndarray:
        return self.shape.get_grid_array(self.orientation)
    def get_position(self) -> CoordinatePair:
        return (self.x, self.y)
    def goto(self, position: CoordinatePair) -> int:
        self.x, self.y = position
    def move(self, dx=0, dy=0) -> int:
        self.x += dx
        self.y += dy
    def rotate(self, rotations = 1) -> None:
        self.set_orientation(self.orientation + rotations)
    def set_orientation(self, orientation: int) -> int:
        self.orientation = orientation % len(self.shape.orientations)
    def copy(self) -> Self:
        return self.__class__(self.shape, (self.x, self.y), self.orientation)
    def __iter__(self) -> Generator[tuple[int, CoordinatePair], None, None]:
        for row in range(self.get_height()):
            for col in range(self.get_width()):
                yield (self.get_grid_array()[row][col], (self.y + row, self.x + col))
    def __str__(self) -> str:
        return f"{self.__class__.__name__}(x={self.x}, y={self.y}, shape={self.shape}, orientation={self.orientation})"
from .tetromino import Tetromino
from .shape import TetrominoShape
__all__ = [Tetromino, TetrominoShape]
from abc import ABC, abstractmethod
from game_actions import Action
class Player(ABC):
    @abstractmethod
    def get_name(self) -> str:
        pass
    @abstractmethod
    def get_actions(self) -> list[Action]:
        pass
import pygame
from game_actions import Action
from .player import Player
class PygamePlayer(Player):
    DEFAULT_BINDINGS = {
        pygame.K_UP: Action.SPIN,
        pygame.K_DOWN: Action.SOFT_DROP,
        pygame.K_SPACE: Action.HARD_DROP,
        pygame.K_LEFT: Action.LEFT,
        pygame.K_RIGHT: Action.RIGHT,
        pygame.K_c: Action.HOLD,
    }
    def __init__(self, control_map: dict[int: Action]) -> None:
        pygame.init()
        self.control_map = control_map
    def get_name(self) -> str:
        return "Human Player"
    
    def get_actions(self) -> list[Action]:
        pressed = pygame.key.get_pressed()
        return [action for (key, action) in self.control_map.items() if pressed[key]]from .player import Player
from .pygame_player import PygamePlayer
__all__ = [
    Player,
    PygamePlayer
from abc import ABC, abstractmethod
import numpy as np
class BaseLayer(ABC):
    _verbose_name = ""
    
    def __init__(self) -> None:
        super().__init__()
    def __str__(self) -> str:
        return f"<{type(self).__base__.__name__} {self._verbose_name if self._verbose_name else type(self).__name__}>".title()
    def __repr__(self) -> str:
        dict_str = ", ".join(f"{key}={value}" for key, value in self.__dict__.items() if not key.startswith("_"))
        return f"{type(self).__name__}({dict_str})"
    @abstractmethod
    def forward(self, inputs: np.ndarray) -> np.ndarray:
        pass
    
    @abstractmethod
    def backward(self, inputs: np.ndarray, output_gradient: np.ndarray, learning_rate: np.ndarray) -> np.ndarray:
        pass
    def save_params(self) -> tuple:
        """Returns layers mutable data, not the entire layer"""
        return ()
    
    def load_params(self, params: tuple) -> None:
        """Load is an alternative to training, not for saving entire layer"""
        returnfrom neural_network import activations, layers, losses, network
__all__ = [activations, layers, losses, network]
from abc import ABC, abstractmethod
import numpy as np
from neural_network.base import BaseLayer
class Activation(BaseLayer, ABC):
    def __call__(self, x: np.ndarray) -> np.ndarray:
        return self.activation(x)
    def __init__(self) -> None:
        super().__init__()
    def forward(self, inputs):
        return self.activation(inputs)
    def backward(self, inputs, output_gradient, learning_rate=None):
        return output_gradient * self.activation_prime(inputs)
    @abstractmethod
    def activation(self, x: np.ndarray) -> np.ndarray:
        pass
    @abstractmethod
    def activation_prime(self, x: np.ndarray) -> np.ndarray:
        pass
class BinaryStep(Activation):
    """ 
    Binary Step.
    Cons: Only works for binary outputs, bad for back prop because gradient is always 0.
    """
    _verbose_name = "binary step"
    def __init__(self, threshold=0.0):
        super().__init__()
        self.threshold = threshold
    def activation(self, x):
        return np.where(x < self.threshold, 0.0, 1.0)
    def activation_prime(self, x):
        return np.zeros_like(x, dtype=float)
class Sigmoid(Activation):
    """
    Sigmoid / Logistic Activation Function.
    Creates S shape between 0 and 1.
    Good for models that predicting probability since it is between 0 and 1.
    Pros: Smooth gradient so no jumping around, always between 0 and 1.
    Cons: Little change in output from values ~3 or more from zero.
    """
    _verbose_name = "logistic activation function"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        # return 1.0 / (1.0 + np.exp(-x))
        return np.where(x < 0, np.exp(x) / (1.0 + np.exp(x)), 1.0 / (1.0 + np.exp(-x)))
    def activation_prime(self, output_gradient):
        s = self(output_gradient)
        return s * (1.0-s)
class HardSigmoid(Activation):
    """
    Hard Sigmoid.
    Fast approximation of sigmoid.
    """
    _verbose_name = "hard sigmoid"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        x = 0.2 * x + 0.5
        return np.clip(x, 0.0, 1.0)
    def activation_prime(self, x):
        return np.where((x >= -2.5) & (x <= 2.5), 0.2, 0.0)
class Tanh(Activation):
    """
    Tanh / Hyperbolic Tangent.
    Similar to sigmoid, but between -1 and 1. It is usually used in hidden layers
    Pros: Zero centered so it can be seen as either negative, positive, or neutral;
    and it keeps the data centered making learning easier because gradients can move both positive or negative
    Cons: Same problem as sigmoid, little change in values ~3 or more from zero.
    """
    _verbose_name = "hyperbolic tangent"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        return np.tanh(x)
    def activation_prime(self, x):
        return 1 - np.tanh(x) ** 2
class Affine(Activation):
    """
    Affine.
    Just y = mx + b
    """
    _verbose_name = "affine"
    def __init__(self, slope=1, intercept=0):
        super().__init__()
        self.slope = slope
        self.intercept = intercept
    def activation(self, x):
        return self.slope * x + self.intercept
    def activation_prime(self, x):
        return np.ones_like(x, dtype=float) * self.slope
class Linear(Activation):
    """ 
    Linear / Identity / No activation.
    Cons: All layers will just become basically one layer, bad for back prop because gradient is always 1.
    """
    _verbose_name = "linear"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        return x
    def activation_prime(self, x):
        return np.ones_like(x, dtype=float)
class Exponential(Activation):
    _verbose_name = "Exponential"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        return np.exp(x)
    def activation_prime(self, x):
        return np.exp(x)
class ReLU(Activation):
    """
    Rectified Linear Unit.
    Relu does not activate all the neurons, only a subset, reducing needed calculations.
    Pros: Efficient because it sets negative values to 0 and leaves rest the same, this gives it linearity and non-saturation properties
    Cons: Can make "dead" neurons that don't have their weights and biases updated and that never get activated, also since it sets all negative to zero it loses some training data
    """
    _verbose_name = "rectified linear unit"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        return np.maximum(x, 0.0)
    def activation_prime(self, x):
        return (x > 0).astype(float)
class LeakyReLU(Activation):
    """
    Leaky Rectified Linear Unit.
    Pros: Same as relu but enables back prop even for negative values
    Cons: Time consuming to train with gradient decent due to small slope for negative values
    """
    _verbose_name = "leaky rectified linear unit"
    def __init__(self, alpha=0.1):
        super().__init__()
        self.alpha = alpha
    def activation(self, x):
        return np.where(x > 0, x, x * self.alpha)
    def activation_prime(self, x):
        return np.where(x > 0, 1.0, self.alpha)
class ELU(Activation):
    """
    Exponential Linear Units.
    Pros: Same as relu but is smooths softly, avoids dead neurons
    Cons: Increased computation time because of exp, no learning of alpha value, can have exploding gradient problem
    """
    _verbose_name = "exponential linear units"
    def __init__(self, alpha=1):
        super().__init__()
        self.alpha = alpha
    def activation(self, x):
        return np.where(x > 0, x, self.alpha * (np.exp(x) - 1))
    def activation_prime(self, x):
        return np.where(x > 0, 1.0, self.alpha * np.exp(x))
class GELU(Activation):
    """
    Approximate Gaussian Error Linear Unit.
    Pros: Like ReLU, buts weights inputs by their value instead of sign
    """
    _verbose_name = "approximate gaussian error linear unit"
    def __init__(self):
        super().__init__()
        # self.approximate = approximate
    def activation(self, x):
        return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x ** 3)))
    def activation_prime(self, x):
        erf_prime = (2 / np.sqrt(np.pi)) * np.exp(-((x / np.sqrt(2)) ** 2))
        approx = np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x ** 3))
        return 0.5 + (0.5 * approx) + ((0.5 * x * erf_prime) / np.sqrt(2))
class SELU(Activation):
    """
    Scaled Exponential Linear Unit.
    Pros: Can be good when used with correct weight initialization and regularization 
    Cons: Need special initialization and regularization 
    """
    _verbose_name = "scaled exponential linear unit"
    def __init__(self):
        super().__init__()
        self.alpha = 1.6732632423543772848170429916717
        self.scale = 1.0507009873554804934193349852946
        self._elu = ELU(alpha=self.alpha)
    def activation(self, x):
        return self.scale * self._elu(x)
    def activation_prime(self, x):
        return self.scale * np.where(x >= 0, 1.0, np.exp(x) * self.alpha)
class Swish(Activation):
    """
    Swish.
    Pros: smoother curve then ReLU, large negative numbers are zeroed out while smaller ones are kept
    """
    _verbose_name = "swish"
    def __init__(self):
        super().__init__()
        # self.beta = beta
        self._sigmoid = Sigmoid()
    def activation(self, x):
        return x * self._sigmoid(x)
    def activation_prime(self, x):
        return x * self._sigmoid.activation_prime(x) + self._sigmoid(x)
class Softplus(Activation):
    """
    Softplus.
    Output is always positive
    Pros: Like a smooth ReLU
    Cons: Slowish to compute compared to ReLU
    """
    _verbose_name = "softplus"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        return np.log(np.exp(x) + 1)
    def activation_prime(self, x):
        exp_x = np.exp(x)
        return exp_x / (exp_x + 1)
class Softmax(Activation):
    """
    Softmax.
    Good for output layer as it makes sum of 1.
    """
    _verbose_name = "softmax"
    def __init__(self):
        super().__init__()
    def activation(self, x):
        e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return e_x / np.sum(e_x, axis=-1, keepdims=True)
    def backward(self, inputs, output_gradient, learning_rate=None):
        # Create uninitialized array
        input_derivative = np.empty_like(output_gradient)
        output = self(inputs)
        # Enumerate outputs and gradients
        for index, (single_output, single_grad) in enumerate(zip(output, output_gradient)):
            single_output = single_output.reshape(-1, 1)
            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)
            input_derivative[index] = np.dot(jacobian_matrix, single_grad)
        return input_derivative
    def activation_prime(self, x, output_gradient):
        return self.backward(x, output_gradient)from activations import *
from matplotlib import pyplot as plt
def graph_all(x: np.ndarray = None) -> None:
    funcs: list[Activation] = [BinaryStep, Sigmoid, HardSigmoid, Tanh, Affine, Linear,
                               Exponential, ReLU, LeakyReLU, ELU, GELU, SELU, Swish, Softplus, Softmax]
    for activation in funcs:
        graph_activation(activation, x)
def graph_activation(activation: Activation, x: np.ndarray = None):
    if x is None: x = np.arange(-5, 5, 0.01)
    if x.ndim == 1: x = x.reshape((1, ) + x.shape)
    y = activation(x)
    plt.title(repr(activation))
    plt.axhline(0, color='dimgrey', linewidth=1)
    plt.axvline(0, color='dimgrey', linewidth=1)
    # plt.ylim(-1.2, 1.2)
    plt.plot(x, y, label="activation")
    plt.plot(x, activation.activation_prime(x), label="activation prime")
    print(activation)
    plt.legend(loc="best")
    plt.grid(True)
    plt.show()
from .activations import BinaryStep, Sigmoid, HardSigmoid, Tanh, Affine, Linear, Exponential, ReLU, LeakyReLU, ELU, GELU, SELU, Swish, Softplus, Softmax
__all__ = [BinaryStep, Sigmoid, HardSigmoid, Tanh, Affine, Linear,
           Exponential, ReLU, LeakyReLU, ELU, GELU, SELU, Swish, Softplus, Softmax]from abc import ABC, abstractmethod
import numpy as np
from neural_network.base import BaseLayer
class Layer(BaseLayer, ABC):
    def __init__(self) -> None:
        super().__init__()
# every class should only take how many outputs and then the next layer will use that for n_inputs when model.compile()
# class Flatten(Layer):
# class Input(Layer)
# class Conv(Layer)
# class MaxPooling(Layer)
# class Dropout(Layer)
class Reshape(Layer):
    _verbose_name = "reshape"
    
    def __init__(self, in_shape, out_shape) -> None:
        super().__init__()
        self.in_shape = in_shape
        self.out_shape = out_shape
    def forward(self, inputs):
        return inputs.reshape(-1, *self.out_shape)
    
    def backward(self, inputs, output_gradient, learning_rate):
        return inputs * output_gradient.reshape(-1, *self.in_shape)
class Dense(Layer):
    _verbose_name = "fully connected layer"
    
    def __init__(self, n_inputs, n_outputs) -> None:
        self.weights = np.random.randn(n_inputs, n_outputs) * 0.01
        self.biases = np.zeros((1, n_outputs), dtype=np.float64)
    
    def rand_shift(self, weights_scale: float = 0.01, biases_scale: float = 0.01) -> None:
        self.weights = self.weights + np.random.random(self.weights.shape) * biases_scale
        self.biases = self.biases + np.random.random(self.biases.shape) * weights_scale
    
    def forward(self, inputs):
        return np.dot(inputs, self.weights) + self.biases
    def backward(self, inputs, output_gradient, learning_rate):
        weights_gradient = np.dot(inputs.T, output_gradient)
        bias_gradient = np.sum(output_gradient, axis=0, keepdims=True)
        input_gradient = np.dot(output_gradient, self.weights.T)
        
        self.weights = self.weights - learning_rate * weights_gradient
        self.biases = self.biases - learning_rate * bias_gradient
        
        return input_gradient
    
    def save_params(self) -> tuple:
        return (self.weights.tobytes(), self.biases.tobytes())
    
    def load_params(self, params: tuple) -> None:
        weights, biases = params
        
        weights = np.frombuffer(weights, dtype=np.float64, like=self.weights).reshape(self.weights.shape)
        biases = np.frombuffer(biases, dtype=np.float64, like=self.biases).reshape(self.biases.shape)
        
        self.weights = weights
        self.biases = biasesfrom .layers import Reshape, Dense
__all__ = [Reshape, Dense]from abc import ABC, abstractmethod
import numpy as np
from neural_network.base import BaseLayer
class Loss(BaseLayer, ABC):
    def __init__(self, categorical_labels: bool = None) -> None:
        super().__init__()
        self.categorical_labels = categorical_labels
    def _labels_to_one_hot(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
        classes = np.size(y_pred, 1)
        y_true = np.eye(classes)[y_true]
        return y_true
    
    def forward(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        if self.categorical_labels or (self.categorical_labels is None and y_true.ndim == 1):
            y_true = self._labels_to_one_hot(y_true, y_pred)
        
        loss = self.loss(y_true, y_pred)
        return np.mean(loss)
    
    def backward(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
        if self.categorical_labels or (self.categorical_labels is None and y_true.ndim == 1):
            y_true = self._labels_to_one_hot(y_true, y_pred)
            
        samples = np.size(y_true, 0)
        loss_prime = self.loss_prime(y_true, y_pred)
        
        return loss_prime / samples
    
    @abstractmethod
    def loss(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
        pass
        
    def loss_prime(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
        pass
    
class MSE(Loss):
    _verbose_name = "mean squared error"
    
    def __init__(self, categorical_labels: bool = False) -> None:
        super().__init__(categorical_labels)
    
    def loss(self, y_true, y_pred):
        return np.square(y_true - y_pred)
    
    def loss_prime(self, y_true, y_pred):
        return 2 * (y_pred - y_true)
    
class BinaryCrossEntropy(Loss):
    _verbose_name = "binary cross entropy"
    
    def __init__(self, categorical_labels: bool = None) -> None:
        super().__init__(categorical_labels)
    
    def loss(self, y_true, y_pred):
        return -((y_true * np.log(y_pred)) + ((1 - y_true) * np.log(1 - y_pred)))
    
    def loss_prime(self, y_true, y_pred):
        return (1 - y_true) / (1 - y_pred) - y_true / y_pred
    
class CategoricalCrossEntropy(Loss):
    _verbose_name = "Categorical cross entropy"
    
    def __init__(self, categorical_labels: bool = None) -> None:
        super().__init__(categorical_labels)
    
    def loss(self, y_true, y_pred):
        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)
        return -np.log(np.sum(y_pred * y_true, axis=1))
         
    
    def loss_prime(self, y_true, y_pred):
        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)
        return -y_true / y_predfrom .losses import MSE, BinaryCrossEntropy, CategoricalCrossEntropy
__all__ = [MSE, BinaryCrossEntropy, CategoricalCrossEntropy]import pickle
import numpy as np
from neural_network.losses.losses import Loss
from neural_network.base import BaseLayer
# at some point add compile step where optimizations could be made and Dense Layers could find how many inputs they have
#  _init_params should also return self and any other layers to add (for example Dense could return itself and an activation)
# also save _init_params for model save / load
def n_split_array(arr, n_size, *, keep_extra=True):
    """split arr into chunks of size n with extra added on end if keep_extra is true"""
    if n_size is None: return arr
        
    if len(arr) < n_size:
        return [arr] if keep_extra else []
    
    div, extra = divmod(len(arr), n_size)
    
    a, b = np.split(arr, [len(arr) - extra])
    
    return np.array_split(a, div) + ([b] if (len(b) and keep_extra) else [])
def same_shuffle(*arrays):
    """shuffle 2 arrays """
    order = np.arange(np.size(arrays[0], 0))
    np.random.shuffle(order)
    return tuple(array[order] for array in arrays)
class Network:
    def __init__(self, layers: list[BaseLayer], loss: Loss, preprocess: list = []) -> None:
        self.layers = layers
        self.loss = loss
        self.reprocesses = preprocess
    
    def compute(self, inputs: np.ndarray) -> np.ndarray:
        
        for proc in self.reprocesses:
            inputs = proc(inputs)
        
        for layer in self.layers:
            inputs = layer.forward(inputs)
        return inputs
    
    
    def train(self, x: np.ndarray, y: np.ndarray, learning_rate: float = 0.001, batch_size: int = 32, epochs: int = 1, shuffle: bool = True, logging = True):
        for proc in self.reprocesses:
            x = proc(x)
            
        max_str_len = 0
        
        loss = None
        
        last_percent_complete = -1
         
        for epoch in range(epochs):
            if shuffle:
                x, y = same_shuffle(x, y)
            x_split, y_split = n_split_array(x, batch_size), n_split_array(y, batch_size)
            for batch, (x_batch, y_batch) in enumerate(zip(x_split, y_split)):                      
                zs = [x_batch]
                for layer in self.layers:
                    activation = layer.forward(zs[-1])
                    zs.append(activation)
                    
                # todo add more logging options and make it so it ends at 100 and batch at 50 by +1
                    
                output = zs.pop()
                                
                loss = self.loss.forward(y_batch, output)
                
                percent_complete = int((batch + len(x_split) * epoch) / (len(x_split) * epochs) * 100)
                if logging and (percent_complete > last_percent_complete or batch == 0):
                    last_percent_complete = percent_complete
                    message = f"{percent_complete}% complete. {epoch=}, {batch=}, {loss=}"
                    max_str_len = max(max_str_len, len(message))
                    print(message.ljust(max_str_len), end=("\n" if batch == 0 else "\r"))
                                   
                grad = self.loss.backward(y_batch, output)
                
                for layer, activation in zip(reversed(self.layers), reversed(zs)):
                    grad = layer.backward(activation, grad, learning_rate)
            
        if logging: print(f"100% complete. finished, {loss=}".ljust(max_str_len))
    def dump(self, file_path: str) -> None:
        with open(file_path.lstrip(".pkl") + ".pkl", "wb") as file:
            file.write(self.dumps())
    
    def dumps(self) -> bytes:
        return pickle.dumps(
            tuple(layer.save_params() for layer in self.layers)
        )
    
    def load(self, file_pah: str) -> None:
        with open(file_pah + ".pkl", "rb") as file:
            self.loads(file.read())
    
    def loads(self, params: bytes) -> None:
        for layer, saved_layer_data in zip(self.layers, pickle.loads(params)):
            layer.load_params(saved_layer_data)from .network import Network
__all__ = [Network]import numpy as np
Dot product of two arrays. Specifically,
- If both `a` and `b` are 1-D arrays, it is inner product of vectors
    (without complex conjugation).
- If both `a` and `b` are 2-D arrays, it is matrix multiplication,
    but using matmul or a @ b is preferred.
- If either `a` or `b` is 0-D (scalar), it is equivalent to multiply using multiply or a * b is preferred.
- If `a` is an N-D array and `b` is a 1-D array, it is a sum product over the last axis of `a` and `b`.
- If `a` is an N-D array and `b` is an M-D array (where M>=2), it is a
    sum product over the last axis of `a` and the second-to-last axis of `b`
Only works if the last dimension of `a` is the same size as the second-to-last dimension of `b`.
# for 2d only:
# The width of `a` must be the same as the height `b`.
# 'a' sets the height and 'b' sets the width
x = np.array([[1, 2, 3]])
y = np.array([[4, 5, 6]])
print(x.shape, y.T.shape, x.T.shape[-1] == y.shape[-2])
print(np.dot(x, y.T))
[[1, 2, 3]] * [[4],
               [5],
               [6]]
[[1*4 + 2*5 + 3*6]]
[[4 + 10 + 18]]
[[32]]
print()
print(x.T.shape, y.shape, x.T.shape[-1] == y.shape[-2])
print(np.dot(x.T, y))
# [[1], [2], [3]] * [[4, 5, 6]]
# [[1*4, 2*4, 3*4], [[1*5, 2*5, 3*5]], [[1*6, 2*6, 3*6]]]
# [[4, 8, 12], [5, 10, 15], [6, 12, 18]]
print()
# different shape with T in back
x = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]])
y = np.array([[4, 5, 6], [4, 5, 6], [4, 5, 6], [4, 5, 6]])
print(x.shape, y.T.shape, x.shape[-1] == y.T.shape[-2])
print(np.dot(x, y.T))
print()
# same shape with T in front
print(x.T.shape, y.shape, x.T.shape[-1] == y.shape[-2])
print(np.dot(x.T, y))
print()import numpy as np
# input neurons: 2, output neurons: 3
# pretend all values are decimals not hole numbers, just using ints for simple viewing
inputs = np.array([1, 2])
weights = np.array([[3, 4, 5],
                    [6, 7, 8]])
biases = np.array([9, 10, 11])
def relu(x): return np.maximum(x, 0)
activation_function = relu
actual = [10, 20, 30]
def mse(true, actual): return np.mean(np.square(true - actual))
def categorical_cross_entropy(y_true, y_pred): return np.mean(-np.sum(y_true * np.log(np.clip(y_pred, 1e-7, 1-1e-7))))
error_function = mse
each row of weights aligns with one input, each column with one output
    3 
[1] 4   [1*3 + 2*6] = [15]
    5 
        [1*4 + 2*7] = [18]
    6
[2] 7   [1*5 + 2*8] = [21]
    8
# [1, 2] * [[3, 4, 5], [6, 7, 8]]
# [1*3 + 2*6, 1*4 + 2*7, 1*5 + 2*8]
# [3 + 12, 4 + 14, 5 + 16]
# [15, 18, 21]
prediction_step_1 = np.dot(inputs, weights)
print("inputs * weights =", prediction_step_1)
print(f"{inputs.tolist()} * {weights.tolist()} =", prediction_step_1.tolist())
print()
# [15, 18, 22] + [15, 18, 21]
# [15 + 9, 18 + 10, 21 + 11]
# [24, 28, 32]
prediction_step_2 = prediction_step_1 + biases
print("inputs * weights + biases =", prediction_step_2)
print(f"{prediction_step_1.tolist()} + {biases.tolist()} =", prediction_step_2.tolist())
print()
# relu([24, 28, 32])
# [max(24, 0), max(28, 0), max(32, 0)])
# [24, 28, 32]
prediction_step_3 = activation_function(prediction_step_2)
print("activation(inputs * weights + biases) =", prediction_step_3)
print(f"{activation_function.__name__}({prediction_step_2.tolist()}) =", prediction_step_3.tolist())
print()
# mean(([10, 20, 30] - [24, 28, 32]) ^ 2)
# mean(([10-24, 20-28, 30-32]) ^ 2)
# mean(([-14, -8, -2]) ** 2)
# mean(([-14^2, -8^2, -2^2]))
# mean(([196, 64, 4]))
# sum([196, 64, 4]) / len([196, 64, 4])
# 264 / 3
# 88
error = error_function(actual, prediction_step_3)
print("error(activation(inputs * weights + biases)) =", error)
print(f"{error_function.__name__}({prediction_step_3.tolist()}) =", error)
print()
import numpy as np
from matplotlib import pyplot as plt
# 3 inputs -> 2 outputs
inputs = np.array([[-1.0, -2.0, 3.0]])
weights = np.array([[3.0, -2.0],
                    [2.0, -2.0],
                    [-1.0, 0.5]])
bias = np.array([1.0, 1.0])
targets = np.random.randint(0, 10, size=(1, 2))
while targets[0][0] == targets[0][1]: targets = np.random.randint(0, 10, size=(2))
learning_rate = 0.001
iterations = 300
outputs = []
losses = []
print(f"Start: Weights={weights.tolist()}, Bias={bias.tolist()}")
for i in range(1, iterations + 1):
    
    # --- forward ---
    
    # n(x) = l(f(x, w, b), y)
    
    # f(x, w, b)
    output = np.dot(inputs, weights) + bias
    
    # l(f(x, w, b), y)
    loss = np.mean(np.square(output - targets))
    
    # --- Save data for graphs --- 
    
    if i == 1:
        print(f"Iteration #0: Loss={loss}, Output={output.tolist()}, Target={targets.tolist()}")
    
    outputs.append(output)
    losses.append(loss)
    
    # --- backward ---
    
    # n'(x) = l'(f(x, w, b), y) * f'(x, w, b)
    
    # loss_grad = l'(f(x, w, b), y)
    loss_grad = 2 * (output - targets) / output.size
        
    # loss_grad * f'(x, w, b) for x
    # loss_grad * weights
    inputs_grad = np.dot(loss_grad, weights.T)
    # [[1, 2]] * [[3, 4, 5], [6, 7, 8]] = 
    # [1*3 + 2*6, 1*4 + 2*7, 1*5 + 2*8] = 
    # [15, 18, 21], shape is same as inputs now
    
    # loss_grad * f'(x, w, b) for w
    # loss_grad * inputs
    weights_grad = np.dot(inputs.T, loss_grad)
    # [[3], [4], [5]] * [[1, 2]] = 
    # [[3*1, 3*2], [4*1, 4*2], [5*1, 5*2]] =
    # [[3, 6], [4, 8], [5, 10]], shape is same as weights now
    
    # loss_grad * f(x, w, b) for b
    # loss_grad
    bias_grad = np.sum(loss_grad, axis=0, keepdims=True)
    # sum columns
    # [[1, 2]], same shape as biases
    
    weights -= learning_rate * weights_grad
    bias_grad -= learning_rate * bias_grad
    
    if i % (iterations // 10) == 0:
        print(f"Iteration #{i}: Loss={loss}, Output={output.tolist()}, Target={targets}")
print(f"End: Weights={weights.tolist()}, Bias={bias.tolist()}")
# --- plotting stuff ---
loss_fig, loss_axis = plt.subplots()
loss_axis.plot(range(iterations), losses, label = "loss")
loss_axis.set_ylim(bottom=0)
loss_axis.set_ylabel("Iterations")
loss_axis.set_xlabel("Loss")
loss_axis.set_title("Loss")
data_fig, data_axis = plt.subplots()
data_axis.plot(range(iterations), [output[0][0] for output in outputs], label = "output1", color = "royalblue")
data_axis.plot(range(iterations), [output[0][1] for output in outputs], label = "output2", color = "darkblue")
data_axis.plot(range(iterations), [targets[0][0] for _ in range(iterations)], label = "target1", color = "lime")
data_axis.plot(range(iterations), [targets[0][1] for _ in range(iterations)], label = "target2", color = "darkgreen")
# data_axis.set_ylim(0, 10)
data_axis.set_ylabel("Iterations")
data_axis.set_xlabel("Layer outputs compared to targets")
data_axis.legend(loc = "best")
data_axis.set_title("Outputs")
plt.show()import numpy as np
from matplotlib import pyplot as plt
inputs = np.array([-1.0, -2.0, 3.0])
weights = np.array([3.0, -2.0, 1.0])
bias = 1.0
target = np.random.randint(0, 10)
while target == 5: target = np.random.randint(0, 10)
learning_rate = 0.001
iterations = 100
outputs = []
losses = []
print(f"Start: Weights={weights.tolist()}, Bias={bias}")
for i in range(1, iterations + 1):
    # n() is full "network", l() is loss, a() is activation, f() is neuron stuff
    # x is input
    
    # --- Forward ---
    
    # n(x, y) = l(a(f(x)), y)
    
    # standard neuron forward pass inputs * weights + bias
    neuron_output = np.dot(inputs, weights) + bias
    
    # ReLU activation function, 0 for negative values and linear for positive
    relu_output = np.maximum(neuron_output, 0)
    
    # calculate error with MSE
    loss = np.mean(np.square(target - relu_output))
    
    # --- Save data for graphs --- 
    
    losses.append(loss)
    outputs.append(relu_output)
    
    if i == 1:
        print(f"Iteration #0: Loss={loss}, Output={relu_output}, Target={target}")
    
    # --- Backward ---
    
    # chain rule: n'(x, y) = l'(a(f(x)), y) * a'(f(x)) * f'(x)
    
    """
    derivative of MSE
    loss_grad = l'(a(f(x)), y)
    
    p is for y_pred, t is y_true
    l(p, t) = sum((t - p)^2) / len(p)
    
    prime for p parameter
    l'(p, t) = sum(2*(t - p)^(2-1)) / len(p)
    Sum can be ignored because other variables can be treated as constants.
    Imagine p is p1, p2, etc and t is t1, t2, etc, since we only focus on 1 parameter at a time
    the other ones can be treated as just constants and the derivative of a constant is 0.
    Since we do all the calculations for all p values at once we can just ignore them.
    l'(p, t) = 2*(t - p) / len(p)
    """
    loss_grad = 2 * (relu_output - target) / relu_output.size
    
    """
    derivative for ReLU
    relu_grad = loss_grad * a'(f(x))
    
    if x < 0 than the output is a constant (0), and the derivative of a constant is 0
    else the output is x making it linear, and the derivative of x*1 is 1
    """
    relu_grad = loss_grad * (neuron_output > 0).astype(float)
    
    """
    neuron_grad = relu_grad * f'(x)
    
    derivative of layer
    
    f(w, x, b) = w * x + b
    
    prime for x parameter
    b can be treated as constant so its derivative is 0, and x is what w is multiped by so it is its gradient
    f'(w, x, b) = x + 0
    f'(w, x, b) = w
    """
    neuron_grad = relu_grad * weights
    
    """
    f'(w, x, b) = w*x + b
    
    prime for w parameter
    b can be treated as constant so its derivative is 0, and w is what x is multiped by so it is its gradient
    f'(w, x, b) = x
    prime for w parameter
    w and x are constant so they can be ignore as their derivative is 0, while b is linear is its derivative is 1 (b = b * 1)
    f'(w, x, b) = 1
    """ 
    weights_grad = relu_grad * inputs
    bias_grad = relu_grad
    
    """multiply grad by learning_rate so it does not change to much and subtract that product since you want to go down the slope (try adding it to see how values run away from target)"""
    weights -= learning_rate * weights_grad
    bias -= learning_rate * bias_grad
    
    if i % (iterations // 10) == 0:
        print(f"Iteration #{i}: Loss={loss}, Output={relu_output}, Target={target}")
print(f"End: Weights={weights.tolist()}, Bias={bias}")
# --- plotting stuff ---
loss_fig, loss_axis = plt.subplots()
loss_axis.plot(range(iterations), losses, label = "loss")
loss_axis.set_ylim(bottom=0)
loss_axis.set_ylabel("Iterations")
loss_axis.set_xlabel("Loss")
loss_axis.set_title("Loss")
data_fig, data_axis = plt.subplots()
data_axis.plot(range(iterations), outputs, label = "output")
data_axis.plot(range(iterations), [target for _ in range(iterations)], label = "target", color = "green")
data_axis.set_ylim(0, 10)
data_axis.set_ylabel("Iterations")
data_axis.set_xlabel("Neuron Output")
data_axis.legend(loc = "best")
data_axis.set_title("Outputs")
plt.show()import numpy as np
from matplotlib import pyplot as plt
from matplotlib.animation import FuncAnimation
# --- back propagation hyper parameters ---
EPOCHS = 2
BATCH_SIZE = 4
LEARNING_RATE = 0.01
# --- function parameters  ---
NOISE_LEVEL = 0.1
TRAIN_LINE_M, TRAIN_LINE_B = 0.5, 0.2
def f(x, *, m=1, b=0, variation=0):
    return (m * x + b) + (np.random.randn(*x.shape) * variation)
# --- create train and test data ---
TRAINING_DATA_SIZE = 2**9
# x_train = np.random.randn(x_train_size, 1)
x_train = np.random.uniform(-2, 2, (TRAINING_DATA_SIZE, 1))
y_train = f(x_train, variation=NOISE_LEVEL, m=TRAIN_LINE_M, b=TRAIN_LINE_B)
# --- initialize weights and biases ---
input_size, output_size = 1, 1
# each row of weights aligns with one input, each column with one output (view example_forward_pass.py)
weights = np.random.randn(input_size, output_size)
# weights = np.array([[-0.7]])
# bias for each output neuron
bias = np.zeros((1, output_size), np.float64)
# ---errors ---
def mse(y_true, y_pred):
    return np.mean(np.square(y_true - y_pred))
def mse_prime(y_true, y_pred):
    return 2 * (y_pred - y_true) / np.size(y_true, 0)
# --- training ---
def n_split_array(arr, n_size, *, keep_extra=True):
    """split arr into chunks of size n with extra added on end if keep_extra is true"""
    if n_size is None: return arr
    div, extra = divmod(np.size(arr, 0), n_size)
    a, b = np.split(arr, [extra]) if extra else arr, None
    return np.array_split(a, div) + ([b] if (b and keep_extra) else [])
def same_shuffle(arrays):
    """shuffle 2 arrays """
    order = np.arange(np.size(arrays[0], 0))
    np.random.shuffle(order)
    return tuple(array[order] for array in arrays)
losses_history = []
params_history = []
x_batches_history, y_batches_history = [], []
for epoch in range(EPOCHS):
    x_train, y_train = same_shuffle((x_train, y_train))
    for x_batch, y_batch in zip(n_split_array(x_train, BATCH_SIZE, keep_extra=False), n_split_array(y_train, BATCH_SIZE, keep_extra=False)):
        # --- forward pass of our one layer on batch ---
        output = np.dot(x_batch, weights) + bias
        loss = mse(y_batch, output)
        # --- backward pass ---
        loss_gradient = mse_prime(y_batch, output)
        
        weights_gradient = np.dot(x_batch.T, loss_gradient)
        weights += LEARNING_RATE * -weights_gradient
        bias_gradient = np.sum(loss_gradient, axis=0, keepdims=True)
        bias += LEARNING_RATE * -bias_gradient
        # output_gradient = np.dot(weights, batch_x.T)
        # --- save data for animation ---
        losses_history.append(loss)
        params_history.append((weights.copy(), bias.copy()))
        x_batches_history.extend(x_batch.flatten().tolist())
        y_batches_history.extend(y_batch.flatten().tolist())
total_runs = len(params_history)
# --- graph parameters ---
TITLE = "one neuron"
STYLE = "dark_background"
GRAPH_HEIGHT_RATIO = (4, 1)
# --- animation parameters ---
ANIMATION_FRAMES_PER_MS = 100
SHOW_TRUE_LINE_AT = -1
FIT_TO_TRAINING_DATA = False
# --- animation / graphing ---
plt.style.use(STYLE)
figure, (dot_axis, loss_axis) = plt.subplots(2, gridspec_kw={"height_ratios": GRAPH_HEIGHT_RATIO})
figure.tight_layout()
dot_axis.set_title(f"{TITLE.title()} {EPOCHS=} {BATCH_SIZE=} {LEARNING_RATE=}")
if FIT_TO_TRAINING_DATA:
    dot_axis.set_xlim(left=np.min(x_train), right=np.max(x_train))
    dot_axis.set_ylim(bottom=np.min(y_train), top=np.max(y_train))
else:
    print(np.max(y_train), np.max(x_train))
    dot_axis.set_xlim(left=0)
    dot_axis.set_ylim(bottom=0)
(past_dots,) = dot_axis.plot([], [], "o", color="grey",  markersize=2, label="past")
(current_dots,) = dot_axis.plot([], [], "o", color="red",  markersize=4, label="batch")
(pred_line,) = dot_axis.plot([], [], markersize=3, label="pred")
(true_line,) = dot_axis.plot([], [], color="green", markersize=3, label="true")
dot_axis.legend(loc="lower right")
loss_axis.set_title("Loss")
loss_axis.set_xlim(left=0, right=total_runs)
loss_axis.set_ylim(bottom=0, top=max(losses_history))
(loss_line,) = loss_axis.plot([], [], label="loss")
animation_lines = [past_dots, current_dots, pred_line, true_line, loss_line]
num_of_batches = TRAINING_DATA_SIZE // BATCH_SIZE
def init():
    for line in animation_lines:
        line.set_data([], [])
        line.set_animated(True)
    return animation_lines
def update(i):
    losses = losses_history[:i+1]
    loss_line.set_data(range(i+1), losses)
        
    if i >= total_runs + SHOW_TRUE_LINE_AT:
        true_line.set_data(x_train, TRAIN_LINE_M * x_train + TRAIN_LINE_B)
    
    epoch_start = i - (i % num_of_batches)
    
    past_points_x, past_points_y = x_batches_history[epoch_start:i], y_batches_history[epoch_start:i]
    past_dots.set_data(past_points_x, past_points_y)
    
    current_batch_x, current_batch_y = x_batches_history[i:i+BATCH_SIZE], y_batches_history[i:i+BATCH_SIZE]
    current_dots.set_data(current_batch_x, current_batch_y)
    
    weights, biases = params_history[i] 
    pred_line.set_data(x_train, np.dot(x_train, weights) + biases)
    
    
    return animation_lines
animation = FuncAnimation(figure, update, frames=total_runs, init_func=init, blit=True, interval=ANIMATION_FRAMES_PER_MS, repeat=False)
figure_manager = plt.get_current_fig_manager()
plt.show()
# save = input("Save (y/N): ").lower().strip() in ("y", "yes", "true")
# if save: animation.save("one_neuron_back_prop.gif")import numpy as np
from matplotlib import pyplot as plt
# 10/10 book would recommend: https://nnfs.io/
def create_data(samples, classes):
    X = np.zeros((samples*classes, 2))
    y = np.zeros(samples*classes, dtype='uint8')
    for class_number in range(classes):
        ix = range(samples*class_number, samples*(class_number+1))
        r = np.linspace(0.0, 1, samples)
        t = np.linspace(class_number*4, (class_number+1)*4, samples) + np.random.randn(samples)*0.2
        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]
        y[ix] = class_number
    return X, y
X, y = create_data(samples=100, classes=3)
# plt.scatter(X[:,0], X[:,1], c = y, cmap="brg")
# plt.show()
class LayerDense:
    def __init__(self, n_inputs, n_outputs) -> None:
        # each row of weights aligns with one input, each column with one output
        self.weights = np.random.randn(n_inputs, n_outputs) * 0.01
        
        # each bias aligns with an output
        self.bias = np.zeros((1, n_outputs), dtype=float)
    def forward(self, input):
        """
        f(inputs, weights, biases) = inputs * weights + biases
        
        inputs = [[1, 2]]
        weights = [[3, 4, 5],
                   [6, 7, 8]]
        bias = [9, 10, 11]
        
        inputs       1,            2
                  /  |  \       /  |  \ 
        weights   3  4  5,      6  7  8    # imagine that both lines of a type went to the same neuron
        
        np.dot  1*3+2*6, 1*4+2*7, 1*5+2*8
                  3+12,    4+14,    5+16
                   15,      18,      21
                   
        bias       9,       10,      11
        
        np.add   15+9    10+18     21+11
        
        output     24      28        32
        """
        
        self.inputs = input
        self.outputs = np.dot(self.inputs, self.weights) + self.bias
    def backward(self, outputs_grad):
        """
        f(inputs, weights, biases) = inputs * weights + biases
        
        n(inputs) = f2(f(inputs, weights, biases), ...)
        n'(inputs) = f2'(f(inputs, weights, biases)) * f'(inputs, weights, biases)
        n'(inputs) = output_grad * f'(inputs, weights, biases)
        """
        
        """
        for weights
        f'(inputs, weights, biases) = inputs
        
        The width of `a` must be the same as the height `b`.
        'a' sets the height and 'b' sets the width
        
        batch_size = b = 1
        
        inputs = [[1, 2]]           shape = (b, 2), shape.T = (2, b)
        outputs_grad = [[3, 4, 5]]  shape = (b, 3)
        weights = [[3, 4, 5],       shape = (2, 3) <-- target
                   [6, 7, 8]]
                   
        solution: use inputs.T as first since it has correct height in wrong place, and its width will match the height of b.
        b has correct width so leave it as is, and the height will match the width of inputs.T
        """
        self.weights_grad = np.dot(self.inputs.T, outputs_grad)
        
        """
        for biases
        f'(inputs, weights, biases) = 1
        
        batch_size = b = 4
        output_grad = [[3, 4, 5],   shape = (b, 3)
                       [3, 4, 5],
                       [3, 4, 5],
                       [3, 4, 5]]
                       
        bias = [[9, 10, 11]]        shape = (1, 3)
        
        solution: sum down the columns, don't mean since with batches the goal is to do the work of many passes in one
        """
        self.bias_grad = np.sum(outputs_grad, axis=1, keepdims=True)
        """
        The width of `a` must be the same as the height `b`.
        'a' sets the height and 'b' sets the width
        
        for inputs
        f'(inputs, weights, biases) = weights
        
        batch_size = b = 1
        
        weights = [[3, 4, 5],       shape = (2, 3), shape.T = (3, 2)
                   [6, 7, 8]]
        outputs_grad = [[3, 4, 5]]  shape = (b, 3)
        inputs = [[1, 2]]           shape = (b, 2) <-- target
        """
        self.inputs_grad = np.dot(outputs_grad, self.weights.T)
        
class ActivationReLU:
    def forward(self, inputs):
        self.inputs = inputs
        """
        ReLU is 0 for all numbers bellow 0 and linear for numbers greater than zero
        """
        self.outputs = np.maximum(inputs, 0)
    
    def backward(self, outputs_grad):
        """
        0 is constant so it has a gradient of 0, if its greater than zero it is linear giving it a gradient of 1
        """
        inputs_grad = (self.inputs > 0).astype(float)
        self.inputs_grad = np.multiply(inputs_grad, outputs_grad)
class ActivationSoftmax:
    def forward(self, inputs):
        """
        softmax takes a row of values and converts into how likely that values is from 0 to 1, always with a sum of 1
        
        x = [[-1, 0.5, 1]]
        
        softmax(x) = [[0.07769558, 0.34820743, 0.57409699]]
        
        7.76%, 34.82%, 57.40%
        
        sum([[0.07769558, 0.34820743, 0.57409699]]) = 1.0
        
        S(Z_i) = exp(Z_i) / sum(exp(Z))
        """
        
        # exp makes all values positive with the more negative a number is the closer to 0 it is
        # the highest value of each row is subtracted to prevent exponential from overflowing, this has no effect on the final output though
        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))
        # since all values are now positive you can get what percent chance they are likely by
        self.outputs = exp_values / np.sum(exp_values, axis=1, keepdims=True)
    
    def backward(self, outputs_grad):      
        """
        thanks https://youtu.be/09c7bkxpv9I
        
        Z = [Z_1, Z_2, Z_3]
        --- Softmax ---
        S(Z_i) = exp(Z_i) / (exp(Z_1) + exp(Z_2) + exp(Z_3))
        S(Z_i) = exp(Z_i) / sum(exp(Z))
        --- Grad for Z_1 if i == j ---
        S(Z_1) = exp(Z_1) / (exp(Z_1) + exp(Z_2) + exp(Z_3))
        gradient rule for division:
        f(x) = g(x) / h(x)
        f'(x) = (g'(x) * h(x) - g(x) * h'(x)) / h(x)^2
        S(Z_1) = (exp(Z_1) * (exp(Z_1) + exp(Z_2) + exp(Z3)) - exp(Z_1) * (exp(Z_1) + exp(Z_2) + exp(Z_3))) / (exp(Z_1) + exp(Z_2) + exp(Z_3))^2
        other variables are treated as constants and the derivative of a added constant is 0
        S'(Z_1) = (exp(Z_1) * (exp(Z_1) + exp(Z_2) + exp(Z3)) - exp(Z_1) * (exp(Z_1) + 0 + 0)) / (exp(Z_1) + exp(Z_2) + exp(Z3))^2
        replace with sums for readability
        S'(Z_1) = (exp(Z_1) * sum(exp(Z)) - exp(Z_1) * exp(Z_1)) / sum(exp(Z))^2
        reorganize
        instead of x*y - x*x subtract the x x times before so it is x*(y-x)
        (10 * 7 - 10 * 2) = 50
        (10 * (7 - 2) = 50
        S'(Z_1) = exp(Z_1) * (sum(exp(Z)) - exp(Z_1)) / sum(exp(Z))^2
        split
        S'(Z_1) = exp(Z_1) * (sum(exp(Z)) - exp(Z_1)) / sum(exp(Z)) * sum(exp(Z))
        S'(Z_1) = (exp(Z_1) / sum(exp(Z))) * ((sum(exp(Z)) - exp(Z_1))) / sum(exp(Z))) 
        
        divide by denominator for second part  
        (10 - 3) / 4 = 1.75
        10 / 4 - 3 / 4 = 1.75
        
        (4 - 2) / 4 = 0.5
        1 - (2 / 4) = 0.5
        
        S'(Z_1) = (exp(Z_1) / sum(exp(Z))) * (1 - exp(Z_1) / sum(exp(Z)))
         
        replace
        S'(Z_1) = S(Z_1) * (1 - S(Z_1))
        
        --- Grad for Z_1 if i != j ---
        S(Z_2) = exp(Z_2) / (exp(Z_1) + exp(Z_2) + exp(Z_3))
        
        S'(Z_2) = (0 * sum(exp(Z)) - exp(Z_2) * (exp(Z_1) + 0 + 0)) / (exp(Z_1) + exp(Z_2) + exp(Z_3))**2
        
        get rid of zeros and replace with sum
        S'(Z_2) = (-exp(Z_2) * exp(Z_1)) / sum(exp(Z))**2
        
        split
        S'(Z_2) = (-exp(Z_2) * exp(Z_1)) / (sum(exp(Z)) * sum(exp(Z)))
        S'(Z_2) = (-exp(Z_2) / sum(exp(Z))) * (exp(Z_1) / sum(exp(Z)))
        
        replace with S
        
        --- Final ---
        
        for Z_1
        if i==j: S'(Z_1) = S(Z_1) * (1 - S(Z_1))
        else S'(Z_2) = -S(Z_2) * S(Z_1)
        
        combine
        S'(Z_i) = S(Z_1) * (int(i==j) - S(Z_j))
        """
     
        # create blank array for final grad
        self.inputs_grad = np.empty_like(outputs_grad)
        
        for index, (single_output, single_grad) in enumerate(zip(self.outputs, outputs_grad)):
            # output = [1, 2, 3, 4]
            # grad = [1, 1, 1, 1]
            
            # convert single_output to 2d
            single_output = single_output.reshape(1, -1)
            # output = [[1, 2, 3, 4]]
            
            """
            i is number softmax is being used on, j number we are getting the gradient of 
            
            S(Z_i) = exp(Z_i) / sum(exp(Z))
            S'(Z_j) = S(Z_i) * (int(i==j) - S(Z_j))
            
            reformat to:
            S'(Z_i) = (i if i==j else 0) - S(Z_i) * S(Z_j)
            
            --- i * j ---
            
            get S(Z_i) * S(Z_j)
            pick any i and j from output and there product is at those indices in this matrix
            np.dot(x.T, x)
            [[ 1,  2,  3,  4],
             [ 2,  4,  6,  8],
             [ 3,  6,  9, 12],
             [ 4,  8, 12, 16]]
             
            --- x - (i * j) ---
            
            get the (i == j) section. 
            Since here it is subtracted from first instead of it being subtracted from S(Z_j) the 
            4 * (1-2) = -4
            4 - (4 * 2) = -4
            
            4 * (0-2) = -8
            0 - (4 * 2) = -8
            
            np.diagflat(x)
            [[1, 0, 0, 0],
             [0, 2, 0, 0],
             [0, 0, 3, 0],
             [0, 0, 0, 4]]
             
            np.diagflat(x) - np.dot(x.T, x)
            [[  0,  -2,  -3,  -4],
             [ -2,  -2,  -6,  -8],
             [ -3,  -6,  -6, -12],
             [ -4,  -8, -12, -12]]
             
            #  --- final ---
            
            pick any i and j to test. pick to indexes from output
            
            derivative for i
            if i==j: S'(Z_i) = S(Z_i) * (1 - S(Z_j))
            if i!=j: S'(Z_j) = -S(Z_j) * S(Z_i)
              
            S'(Z_i)= S(Z_i) * (int(i==j) - S(Z_j))
            """
            
            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output.T, single_output) 
            
            """
            multiply each column by corresponding grad value, then sum it across that row
            np.dot(np.diagflat(x) - np.dot(x.T, x), [1, 1, 1, 1])
            
            [ -9, -18, -27, -36]
            """
            self.inputs_grad[index] = np.dot(jacobian_matrix, single_grad)
            
class LossCategoricalCrossEntropy:
    def calculate(self, outputs_y, y):
        
        self.forward(outputs_y, y)
        
        return np.mean(self.outputs)
    def forward(self, y_pred, y_true):
        # clip value so that there can't be any zeros which would not work with log. Also clip on upper bound to keep it balanced
        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)
        
        if y_true.ndim == 1:
            """
            y_true is list of correct class
            y_pred = [[0.2, 0.7], [0.3, 0.6], [0.1, 0.9]]
            y_true = [1, 0, 1]
            correct_confidences = y_pred[[0, 1, 2], [1, 0, 1]] = [0.7, 0.3, 0.9]
            """
            correct_confidences = y_pred[range(np.size(y_true, axis=-1)), y_true]
        
        elif y_true.ndim == 2:
            """
            y_true is one hot encoded
            
            y_pred = [[0.2, 0.7], [0.3, 0.6], [0.1, 0.9]]
            y_true = [[0, 1], [1, 0], [0, 1]]
        
            y_pred * y_true = [[0, 0.7], [0.3, 0], [0, 0.9]]
            correct_confidences = np.sum([[0, 0.7], [0.3, 0], [0, 0.9]], axis=1) = [0.7, 0.3, 0.9]
            """
            correct_confidences = np.sum(y_pred * y_true, axis=1)
        """
        example of -log, rounded to 1 decimal
        
        -log(0.0) = inf
        -log(0.1) = 2.3
        -log(0.2) = 1.6
        -log(0.3) = 1.2
        -log(0.4) = 0.9
        -log(0.5) = 0.7
        -log(0.6) = 0.5
        -log(0.7) = 0.3
        -log(0.8) = 0.2
        -log(0.9) = 0.1
        -log(1.0) = 0.0
        """
        self.outputs = -np.log(correct_confidences)
    def backward(self, y_pred, y_true):
        n_samples = np.size(y_pred, 0)
        n_labels = np.size(y_pred, -1)
        
        if y_true.ndim == 1:
            # if y_true is list of labels, convert to one hot encoded
            y_true = np.eye(n_labels)[y_true]
            
        # -y_true = [[0, -1, 0], [0, -1, 0], [0, -1, 0]]
        #  y_pred = [[0.3, 0.4, 0.3], [0.2, 0.5, 0.3], [0.4, 0.2, 0.4]]
        # -y_true / y_pred = [[0, -2.5, 0], [0, -2, 0], [0, -5, 0]]
        self.inputs_grad = (-y_true / y_pred) / n_samples
a = ActivationSoftmax()
l = LossCategoricalCrossEntropy()
input = np.array([[0.2, 1.8]])
true = np.array([[0, 1]])
print(input, true)
a.forward(input)
print(a.outputs)
l.forward(a.outputs, true)
print(l.outputs)
l.backward(a.outputs, true)
print(l.inputs_grad)
a.backward(l.inputs_grad)
print(a.inputs_grad)
# dense1 = LayerDense(2, 3)
# activation1 = ActivationReLU()
# dense2 = LayerDense(3, 3)
# activation2 = ActivationSoftmax()
# loss_func = LossCategoricalCrossEntropy()
# dense1.forward(X)
# activation1.forward(dense1.outputs)
# dense2.forward(activation1.outputs)
# activation2.forward(dense2.outputs)
# output = activation2.output
# loss = loss_func.calculate(output, y)
# predictions = np.argmax(output, axis=1)
# if len(y.shape) == 2: class_targets = np.argmax(y, axis=1)
# else: class_targets = y
# accuracy = np.mean(predictions==class_targets)
# print(f"loss = {loss}, accuracy = {accuracy:%}")
# loss_func.backward(output, y)
# print(loss_func.inputs_grad)